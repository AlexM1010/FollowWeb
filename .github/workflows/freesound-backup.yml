# Freesound Backup Workflow
#
# Single source of truth for ALL backup operations in the Freesound pipeline.
# This workflow creates and manages backups of checkpoint data with tier-specific
# retention policies and failure recovery support.
#
# Architecture:
# - Triggered ONLY by: Validation pipeline (final step after Collection ‚Üí Repair ‚Üí Validation)
# - Restores checkpoint from GitHub Actions cache (NEW data only)
# - Creates compressed backup with tier tagging
# - Uploads to PRIMARY backup repository ONLY
# - Applies tier-specific retention policies
# - Manual trigger allowed for testing
#
# Pipeline Flow:
# Collection ‚Üí Repair ‚Üí Validation ‚Üí Backup (this workflow)
# This ensures backup only runs once after the entire pipeline completes successfully
#
# Backup Strategy (simplified):
# - Every 100 nodes ‚Üí v-checkpoint release (14-day retention, max 10)
#   - Single tier, single release, simple retention policy
# - Safety mechanism: Never delete the last remaining backup
#   - If retention policy would delete all backups, keep the most recent one
#   - This prevents data loss if pipelines fail for 14+ days
#
# Backup Reasons (non-collection):
# - recovery: Failure recovery backups ‚Üí v-checkpoint (14-day retention)
# - validated: Validated checkpoints ‚Üí v-checkpoint (14-day retention)
# - scheduled: Periodic backups ‚Üí v-checkpoint (14-day retention)
# - manual: Manual trigger ‚Üí v-checkpoint (14-day retention)
#
# Features:
# - Centralized backup logic: ALL backup operations in one place
# - Consistent tier determination: Single algorithm for all backups
# - Failure recovery: Preserves partial progress when collection fails
# - Atomic operations: Only updates backup list after successful upload
# - Tier-specific retention: Different policies for different backup types
# - Cache-based checkpoint sharing (no repo cloning needed)
# - Comprehensive logging and monitoring
#
# CRITICAL: Only interacts with PRIMARY backup repo (no BACKUP_PAT_SECONDARY)

name: Freesound Backup

on:
  workflow_run:
    workflows: 
      - "Freesound Validation & Visualization"
    types: [completed]
    branches: [main]
  
  workflow_dispatch:
    # Allow manual triggering for testing

# Allow concurrent backups but cancel older ones if new one starts
# This prevents backup queue buildup and allows fast failure
concurrency:
  group: freesound-backup
  cancel-in-progress: true

jobs:
  check-trigger:
    name: Check Backup Trigger Conditions
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      should_backup: ${{ steps.check.outputs.should_backup }}
      skip_reason: ${{ steps.check.outputs.skip_reason }}
      trigger_workflow: ${{ steps.check.outputs.trigger_workflow }}
    steps:
    - name: Evaluate backup conditions
      id: check
      run: |
        echo "Event: ${{ github.event_name }}"
        echo "Workflow: ${{ github.event.workflow_run.name }}"
        echo "Conclusion: ${{ github.event.workflow_run.conclusion }}"
        
        SHOULD_BACKUP="false"
        SKIP_REASON=""
        TRIGGER_WORKFLOW="${{ github.event.workflow_run.name }}"
        
        # Manual trigger - allow for testing
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          SHOULD_BACKUP="true"
          echo "‚úÖ Manual trigger - backup will proceed"
        
        # Validation pipeline - only backup on success (this is the final step in the pipeline)
        elif [ "${{ github.event.workflow_run.name }}" = "Freesound Validation & Visualization" ]; then
          if [ "${{ github.event.workflow_run.conclusion }}" = "success" ]; then
            SHOULD_BACKUP="true"
            echo "‚úÖ Validation pipeline succeeded - backup will proceed"
          else
            SHOULD_BACKUP="false"
            SKIP_REASON="Validation pipeline did not succeed (conclusion: ${{ github.event.workflow_run.conclusion }})"
            echo "‚è≠Ô∏è  Validation pipeline failed - skipping backup"
          fi
        
        # Unknown trigger
        else
          SHOULD_BACKUP="false"
          SKIP_REASON="Unknown trigger: event=${{ github.event_name }}, workflow=${{ github.event.workflow_run.name }}"
          echo "‚ùå Unknown trigger - skipping backup"
        fi
        
        {
          echo "should_backup=$SHOULD_BACKUP"
          echo "skip_reason=$SKIP_REASON"
          echo "trigger_workflow=$TRIGGER_WORKFLOW"
        } >> "$GITHUB_OUTPUT"
        
        # Create summary
        {
          echo "## üîç Backup Trigger Check"
          echo ""
          echo "**Event:** \`${{ github.event_name }}\`"
          if [ -n "$TRIGGER_WORKFLOW" ]; then
            echo "**Triggering Workflow:** \`$TRIGGER_WORKFLOW\`"
            echo "**Workflow Conclusion:** \`${{ github.event.workflow_run.conclusion }}\`"
          fi
          echo "**Should Backup:** \`$SHOULD_BACKUP\`"
          if [ -n "$SKIP_REASON" ]; then
            echo ""
            echo "**‚ö†Ô∏è  Skip Reason:** $SKIP_REASON"
          fi
        } >> "$GITHUB_STEP_SUMMARY"
  
  backup-checkpoint:
    name: Create and Manage Checkpoint Backup
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: check-trigger
    if: needs.check-trigger.outputs.should_backup == 'true'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v6
      with:
        fetch-depth: 1
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: 'FollowWeb/requirements.txt'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r FollowWeb/requirements.txt
    
    - name: Set execution parameters
      id: params
      run: |
        {
          echo "execution_id=$(date +'%Y%m%d_%H%M%S')"
          echo "timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")"
        } >> "$GITHUB_OUTPUT"
    
    - name: Detect backup reason and determine cache strategy
      id: backup_reason
      run: |
        # shellcheck disable=SC2129
        {
          echo "## üíæ Backup Workflow"
          echo ""
          echo "**Configuration:**"
          echo "- Execution ID: \`${{ steps.params.outputs.execution_id }}\`"
          echo "- Trigger: \`${{ github.event_name }}\`"
        } >> "$GITHUB_STEP_SUMMARY"
        
        # Backup is ONLY triggered by upstream workflows (manual/scheduled are skipped)
        upstream_workflow="${{ github.event.workflow_run.name }}"
        upstream_conclusion="${{ github.event.workflow_run.conclusion }}"
          
          {
            echo "- Upstream Workflow: \`$upstream_workflow\`"
            echo "- Upstream Conclusion: \`$upstream_conclusion\`"
            echo "- Upstream Run: [#${{ github.event.workflow_run.run_number }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.event.workflow_run.id }})"
          } >> "$GITHUB_STEP_SUMMARY"
          
          # Determine reason based on upstream workflow and conclusion
          if [ "$upstream_workflow" = "Freesound Nightly Collection" ]; then
            if [ "$upstream_conclusion" = "success" ]; then
              {
                echo "reason=collection_success"
                echo "tier=checkpoint"
              } >> "$GITHUB_OUTPUT"
              {
                echo "- Backup Reason: \`Collection pipeline succeeded\`"
              } >> "$GITHUB_STEP_SUMMARY"
            else
              {
                echo "reason=failure_recovery"
                echo "tier=recovery"
              } >> "$GITHUB_OUTPUT"
              {
                echo "- Backup Reason: \`‚ö†Ô∏è  Failure Recovery (preserving partial progress)\`"
              } >> "$GITHUB_STEP_SUMMARY"
            fi
            {
              echo "use_cache=true"
              echo "cache_key=checkpoint-${{ github.event.workflow_run.id }}"
            } >> "$GITHUB_OUTPUT"
            {
              echo "- Cache Key: \`checkpoint-${{ github.event.workflow_run.id }}\`"
            } >> "$GITHUB_STEP_SUMMARY"
          elif [ "$upstream_workflow" = "Freesound Validation & Visualization" ]; then
            {
              echo "reason=validation_success"
              echo "tier=validated"
              echo "use_cache=true"
              echo "cache_key=checkpoint-${{ github.event.workflow_run.id }}"
            } >> "$GITHUB_OUTPUT"
            {
              echo "- Backup Reason: \`Validation pipeline succeeded\`"
              echo "- Cache Key: \`checkpoint-${{ github.event.workflow_run.id }}\`"
            } >> "$GITHUB_STEP_SUMMARY"
        else
          {
            echo "reason=unknown"
            echo "tier=unknown"
            echo "use_cache=true"
            echo "cache_key=checkpoint-${{ github.event.workflow_run.id }}"
          } >> "$GITHUB_OUTPUT"
          {
            echo "- Backup Reason: \`Unknown workflow trigger\`"
            echo "- Cache Key: \`checkpoint-${{ github.event.workflow_run.id }}\`"
          } >> "$GITHUB_STEP_SUMMARY"
        fi
        
        echo "" >> "$GITHUB_STEP_SUMMARY"

    - name: Restore checkpoint
      if: steps.backup_reason.outputs.use_cache == 'true'
      id: restore
      uses: ./.github/workflows/freesound-checkpoint-restore.yml
      secrets:
        BACKUP_PAT: ${{ secrets.BACKUP_PAT }}
      with:
        run_id: ${{ github.event.workflow_run.id }}
        restore-keys: |
          checkpoint-restored-
          checkpoint-repaired-
          checkpoint-
    
    - name: Monitor cache size after restore
      if: steps.backup_reason.outputs.use_cache == 'true' && steps.restore.outputs.checkpoint_restored == 'true'
      id: cache_monitor
      run: |
        python scripts/cache_monitor.py --checkpoint-dir data/freesound_library
        cache_exit_code=$?
        
        # Log cache size status
        if [ "$cache_exit_code" -eq 2 ]; then
          echo "::warning::Cache size critical - backup is essential to prevent data loss"
        elif [ "$cache_exit_code" -eq 1 ]; then
          echo "::warning::Cache size approaching limit - backup recommended"
        fi
        
        # Always continue with backup (don't fail on cache size warnings)
        exit 0
    
    - name: Check cache restore status
      if: steps.backup_reason.outputs.use_cache == 'true'
      id: cache-check
      run: |
        if [ "${{ steps.restore.outputs.checkpoint_restored }}" != "true" ]; then
          echo "::warning::Cache restore failed - upstream workflow did not save checkpoint"
          {
            echo "## ‚ö†Ô∏è Cache Restore Failed"
            echo ""
            echo "Could not restore checkpoint from cache."
            echo ""
            echo "**Expected cache key:** \`${{ steps.backup_reason.outputs.cache_key }}\`"
            echo ""
            echo "**Action:** Backup skipped (no data to backup)"
          } >> "$GITHUB_STEP_SUMMARY"
          echo "cache_restored=false" >> "$GITHUB_OUTPUT"
          exit 0
        fi
        
        # Verify checkpoint directory exists (basic sanity check)
        if [ ! -d "data/freesound_library" ]; then
          echo "::warning::Cache restored but checkpoint directory not found"
          {
            echo "## ‚ö†Ô∏è Invalid Cache Contents"
            echo ""
            echo "Cache was restored but checkpoint directory is missing."
          } >> "$GITHUB_STEP_SUMMARY"
          echo "cache_restored=false" >> "$GITHUB_OUTPUT"
          exit 0
        fi
        
        echo "cache_restored=true" >> "$GITHUB_OUTPUT"
        echo "‚úÖ Cache restored successfully"
    

    - name: Verify checkpoint integrity
      if: steps.cache-check.outputs.cache_restored == 'true'
      id: verification
      run: |
        {
          echo "**Checkpoint Verification:**"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        # Check if checkpoint directory exists
        if [ ! -d "data/freesound_library" ]; then
          echo "::error::Checkpoint directory not found"
          echo "- ‚ùå Directory not found" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        CHECKPOINT_DIR="data/freesound_library"
        
        # Check required files exist
        missing_files=0
        
        if [ ! -f "$CHECKPOINT_DIR/graph_topology.gpickle" ]; then
          echo "::error::Missing graph_topology.gpickle"
          echo "- ‚ùå Missing: graph_topology.gpickle" >> "$GITHUB_STEP_SUMMARY"
          missing_files=$((missing_files + 1))
        else
          graph_size=$(stat -f%z "$CHECKPOINT_DIR/graph_topology.gpickle" 2>/dev/null || stat -c%s "$CHECKPOINT_DIR/graph_topology.gpickle")
          echo "- ‚úÖ graph_topology.gpickle ($(numfmt --to=iec-i --suffix=B "$graph_size"))" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        if [ ! -f "$CHECKPOINT_DIR/metadata_cache.db" ]; then
          echo "::error::Missing metadata_cache.db"
          echo "- ‚ùå Missing: metadata_cache.db" >> "$GITHUB_STEP_SUMMARY"
          missing_files=$((missing_files + 1))
        else
          db_size=$(stat -f%z "$CHECKPOINT_DIR/metadata_cache.db" 2>/dev/null || stat -c%s "$CHECKPOINT_DIR/metadata_cache.db")
          echo "- ‚úÖ metadata_cache.db ($(numfmt --to=iec-i --suffix=B "$db_size"))" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        if [ ! -f "$CHECKPOINT_DIR/checkpoint_metadata.json" ]; then
          echo "::warning::Missing checkpoint_metadata.json"
          echo "- ‚ö†Ô∏è  Missing: checkpoint_metadata.json" >> "$GITHUB_STEP_SUMMARY"
        else
          meta_size=$(stat -f%z "$CHECKPOINT_DIR/checkpoint_metadata.json" 2>/dev/null || stat -c%s "$CHECKPOINT_DIR/checkpoint_metadata.json")
          echo "- ‚úÖ checkpoint_metadata.json ($(numfmt --to=iec-i --suffix=B "$meta_size"))" >> "$GITHUB_STEP_SUMMARY"
          
          # Extract node count from metadata
          node_count=$(jq -r '.nodes // 0' "$CHECKPOINT_DIR/checkpoint_metadata.json")
          edge_count=$(jq -r '.edges // 0' "$CHECKPOINT_DIR/checkpoint_metadata.json")
          {
            echo "node_count=$node_count"
            echo "edge_count=$edge_count"
          } >> "$GITHUB_OUTPUT"
          {
            echo "- Nodes: \`$node_count\`"
            echo "- Edges: \`$edge_count\`"
          } >> "$GITHUB_STEP_SUMMARY"
        fi
        
        if [ "$missing_files" -gt 0 ]; then
          echo "::error::Checkpoint verification failed - missing critical files"
          exit 1
        fi
        
        # Verify file sizes are reasonable (> 1KB for graph, > 10KB for db)
        if [ "$graph_size" -lt 1024 ]; then
          echo "::error::Graph file too small: $graph_size bytes"
          echo "- ‚ùå Graph file too small" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        if [ "$db_size" -lt 10240 ]; then
          echo "::error::Database file too small: $db_size bytes"
          echo "- ‚ùå Database file too small" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        echo "verification_passed=true" >> "$GITHUB_OUTPUT"
        {
          echo ""
          echo "‚úÖ Checkpoint verification passed"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"

    - name: Create backup archive
      if: steps.verification.outputs.verification_passed == 'true' && steps.cache-check.outputs.cache_restored == 'true'
      id: create_backup
      run: |
        node_count="${{ steps.verification.outputs.node_count }}"
        edge_count="${{ steps.verification.outputs.edge_count }}"
        reason="${{ steps.backup_reason.outputs.reason }}"
        
        # CRITICAL: Prevent 0-node or 0-edge backups from being created
        if [ "$node_count" -eq 0 ]; then
          echo "::error::Cannot create backup with 0 nodes - checkpoint is empty or corrupted"
          {
            echo "**‚ùå Backup Creation Failed**"
            echo ""
            echo "**Reason:** Checkpoint has 0 nodes"
            echo ""
            echo "This indicates an empty or corrupted checkpoint. Refusing to create backup to prevent pipeline corruption."
            echo ""
            echo "**Action Required:** Investigate why checkpoint has no data"
          } >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        # Only reject 0 edges if we have many nodes (edges should have been generated)
        # Allow 0 edges for small checkpoints (< 10 nodes) as edges may not be generated yet
        if [ "$edge_count" -eq 0 ] && [ "$node_count" -ge 10 ]; then
          echo "::error::Cannot create backup with 0 edges - checkpoint graph is incomplete"
          {
            echo "**‚ùå Backup Creation Failed**"
            echo ""
            echo "**Reason:** Checkpoint has $node_count nodes but 0 edges"
            echo ""
            echo "This indicates an incomplete graph (nodes without relationships). Refusing to create backup to prevent pipeline corruption."
            echo ""
            echo "**Note:** Small checkpoints (< 10 nodes) are allowed to have 0 edges during collection."
            echo ""
            echo "**Action Required:** Investigate why edge generation failed"
          } >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        # Show backup decision for collection backups
        if [ "$reason" = "collection_success" ]; then
          {
            echo "**Backup Decision:**"
            echo ""
            echo "- Node Count: \`$node_count\`"
            echo "- Backup Interval: \`100\`"
            echo "- Decision: ‚úÖ Create backup (at interval)"
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"
        fi
        
        {
          echo "**Backup Creation:**"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        # All backups go to v-checkpoint release (single tier)
        release_tag="v-checkpoint"
        
        # Create backup filename
        backup_filename="checkpoint_backup_${node_count}nodes_${{ github.run_id }}.tar.gz"
        
        echo "Creating backup archive: $backup_filename"
        echo "- Release: $release_tag"
        echo "- Reason: $reason"
        
        # Create compressed archive
        tar -czf "$backup_filename" -C data freesound_library/
        
        # Get file size
        backup_size=$(stat -f%z "$backup_filename" 2>/dev/null || stat -c%s "$backup_filename")
        echo "Backup size: $(numfmt --to=iec-i --suffix=B "$backup_size")"
        
        # Create backup metadata JSON using jq
        jq -n \
          --arg timestamp "${{ steps.params.outputs.timestamp }}" \
          --arg run_id "${{ github.run_id }}" \
          --argjson samples "${node_count}" \
          --argjson edges "${edge_count}" \
          --arg validation_status "$([ "$reason" = "validation_success" ] && echo "passed" || echo "unknown")" \
          --arg backup_reason "$reason" \
          --arg release_tag "$release_tag" \
          --argjson file_size_bytes "${backup_size}" \
          --arg workflow_trigger "${{ github.event_name }}" \
          '{
            timestamp: $timestamp,
            run_id: $run_id,
            samples: $samples,
            edges: $edges,
            validation_status: $validation_status,
            backup_reason: $backup_reason,
            release_tag: $release_tag,
            file_size_bytes: $file_size_bytes,
            workflow_trigger: $workflow_trigger
          }' > backup_metadata.json
        
        # Add failure metadata for recovery backups
        if [ "$reason" = "failure_recovery" ]; then
          jq --arg failed_run "${{ github.event.workflow_run.id }}" \
             --argjson samples_preserved "${node_count}" \
             '. + {
               failed_workflow_run: $failed_run,
               samples_preserved: $samples_preserved,
               recovery_backup: true
             }' backup_metadata.json > backup_metadata_tmp.json
          mv backup_metadata_tmp.json backup_metadata.json
        fi
        
        # Display metadata
        {
          echo "Backup metadata:"
          echo "\`\`\`json"
          cat backup_metadata.json
          echo "\`\`\`"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        # Store outputs
        {
          echo "backup_filename=$backup_filename"
          echo "backup_size=$backup_size"
          echo "backup_created=true"
          echo "release_tag=$release_tag"
        } >> "$GITHUB_OUTPUT"

    # Detect silent failures - check if we're backing up stale data
    - name: Detect silent failures
      if: steps.create_backup.outputs.backup_created == 'true'
      env:
        BACKUP_PAT: ${{ secrets.BACKUP_PAT }}
      run: |
        node_count="${{ steps.verification.outputs.node_count }}"
        REPO_OWNER="${{ github.repository_owner }}"
        BACKUP_REPO="${REPO_OWNER}/freesound-backup"
        
        # Get previous backups to check for stale data
        ASSETS_JSON=$(curl -s -H "Authorization: token $BACKUP_PAT" \
          "https://api.github.com/repos/${BACKUP_REPO}/releases/tags/v-checkpoint")
        
        if ! echo "$ASSETS_JSON" | grep -q "Not Found"; then
          # Count how many recent backups have the same node count
          same_count=$(echo "$ASSETS_JSON" | jq -r ".assets | map(select(.name | contains(\"${node_count}nodes\"))) | length")
          
          if [ "$same_count" -ge 3 ]; then
            echo "::warning::Node count has been stuck at $node_count for $same_count backups"
            {
              echo ""
              echo "‚ö†Ô∏è **Potential Silent Failure Detected**"
              echo ""
              echo "The node count has been $node_count for the last $same_count backups."
              echo "This may indicate:"
              echo "- Collection pipeline is not adding new data"
              echo "- Cache sharing is broken"
              echo "- Workflows are using stale checkpoints"
              echo ""
              echo "**Action Required:** Investigate why node count is not increasing"
              echo ""
            } >> "$GITHUB_STEP_SUMMARY"
            
            # Create GitHub issue if this persists for 5+ backups
            if [ "$same_count" -ge 5 ]; then
              echo "::error::CRITICAL: Node count stuck at $node_count for $same_count backups"
              echo "This is a critical silent failure - collection pipeline may be broken"
            fi
          fi
        fi

    - name: Verify backup file integrity
      if: steps.create_backup.outputs.backup_created == 'true'
      id: verify_backup
      run: |
        {
          echo "**Backup Verification:**"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        backup_filename="${{ steps.create_backup.outputs.backup_filename }}"
        
        # Check if backup file exists
        if [ ! -f "$backup_filename" ]; then
          echo "::error::Backup file not found: $backup_filename"
          echo "- ‚ùå Backup file not found" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        # Check file size is reasonable (> 50KB, < 10GB)
        backup_size=$(stat -f%z "$backup_filename" 2>/dev/null || stat -c%s "$backup_filename")
        min_size=51200  # 50KB (allows small test backups)
        max_size=10737418240  # 10GB
        
        if [ "$backup_size" -lt "$min_size" ]; then
          echo "::error::Backup file too small: $(numfmt --to=iec-i --suffix=B "$backup_size") (minimum: 50KB)"
          echo "- ‚ùå Backup file too small: $(numfmt --to=iec-i --suffix=B "$backup_size")" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        if [ "$backup_size" -gt "$max_size" ]; then
          echo "::error::Backup file too large: $(numfmt --to=iec-i --suffix=B "$backup_size") (maximum: 10GB)"
          echo "- ‚ùå Backup file too large: $(numfmt --to=iec-i --suffix=B "$backup_size")" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        echo "- ‚úÖ File size valid: $(numfmt --to=iec-i --suffix=B "$backup_size")" >> "$GITHUB_STEP_SUMMARY"
        
        # Verify archive integrity (can be extracted and list contents)
        echo "Verifying archive can be extracted..."
        archive_contents=$(tar -tzf "$backup_filename" 2>&1)
        tar_exit_code=$?
        
        if [ $tar_exit_code -ne 0 ]; then
          echo "::error::Archive is corrupted or cannot be extracted"
          echo "- ‚ùå Archive corrupted (tar exit code: $tar_exit_code)" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        # Check if archive has any contents
        if [ -z "$archive_contents" ]; then
          echo "::error::Archive is empty (no files)"
          echo "- ‚ùå Archive is empty" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        # Count files in archive
        file_count=$(echo "$archive_contents" | wc -l)
        if [ "$file_count" -lt 3 ]; then
          echo "::error::Archive has too few files ($file_count, expected at least 3)"
          echo "- ‚ùå Archive incomplete ($file_count files)" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        echo "- ‚úÖ Archive integrity verified ($file_count files)" >> "$GITHUB_STEP_SUMMARY"
        
        # Verify required files are in archive
        echo "Verifying required files in archive..."
        required_files=(
          "freesound_library/graph_topology.gpickle"
          "freesound_library/metadata_cache.db"
          "freesound_library/checkpoint_metadata.json"
        )
        
        missing_files=0
        for file in "${required_files[@]}"; do
          if tar -tzf "$backup_filename" "$file" > /dev/null 2>&1; then
            echo "  ‚úì $file"
          else
            echo "::error::Missing required file in archive: $file"
            echo "- ‚ùå Missing: $file" >> "$GITHUB_STEP_SUMMARY"
            missing_files=$((missing_files + 1))
          fi
        done
        
        if [ "$missing_files" -gt 0 ]; then
          echo "::error::Archive missing $missing_files required files"
          exit 1
        fi
        
        echo "- ‚úÖ All required files present" >> "$GITHUB_STEP_SUMMARY"
        
        # Test extraction to temporary directory
        echo "Testing extraction..."
        test_dir=$(mktemp -d)
        if tar -xzf "$backup_filename" -C "$test_dir" > /dev/null 2>&1; then
          echo "- ‚úÖ Test extraction successful" >> "$GITHUB_STEP_SUMMARY"
          rm -rf "$test_dir"
        else
          echo "::error::Failed to extract archive to test directory"
          echo "- ‚ùå Test extraction failed" >> "$GITHUB_STEP_SUMMARY"
          rm -rf "$test_dir"
          exit 1
        fi
        
        {
          echo ""
          echo "‚úÖ Backup verification passed"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        echo "verification_passed=true" >> "$GITHUB_OUTPUT"

    - name: Upload backup to PRIMARY repository
      if: steps.verify_backup.outputs.verification_passed == 'true'
      id: upload_backup
      env:
        BACKUP_PAT: ${{ secrets.BACKUP_PAT }}
      run: |
        {
          echo "**Backup Upload:**"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        # Check if BACKUP_PAT is configured (required)
        if [ -z "$BACKUP_PAT" ]; then
          echo "::error::BACKUP_PAT not configured - cannot upload backup"
          {
            echo "- ‚ùå BACKUP_PAT not configured (CRITICAL)"
          } >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        backup_filename="${{ steps.create_backup.outputs.backup_filename }}"
        release_tag="${{ steps.create_backup.outputs.release_tag }}"
        
        echo "Uploading to release: $release_tag"
        {
          echo "- Release Tag: \`$release_tag\`"
        } >> "$GITHUB_STEP_SUMMARY"
        
        REPO_OWNER="${{ github.repository_owner }}"
        BACKUP_REPO="${REPO_OWNER}/freesound-backup"
        
        # Get release ID for the appropriate tag
        RELEASE_JSON=$(curl -s -H "Authorization: token $BACKUP_PAT" \
          "https://api.github.com/repos/${BACKUP_REPO}/releases/tags/${release_tag}")
        
        RELEASE_ID=$(echo "$RELEASE_JSON" | jq -r '.id')
        
        if [ "$RELEASE_ID" = "null" ] || [ -z "$RELEASE_ID" ]; then
          echo "::warning::Release ${release_tag} not found - creating it now"
          {
            echo "- ‚ö†Ô∏è  Release not found: \`${release_tag}\`"
            echo "- üîß Creating release automatically..."
          } >> "$GITHUB_STEP_SUMMARY"
          
          # Create the release
          CREATE_RESPONSE=$(curl -s -X POST \
            -H "Authorization: token $BACKUP_PAT" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${BACKUP_REPO}/releases" \
            -d "{
              \"tag_name\": \"${release_tag}\",
              \"name\": \"Latest Checkpoint\",
              \"body\": \"Rolling checkpoint storage for Freesound pipeline. This release is automatically updated with the latest checkpoint.\",
              \"draft\": false,
              \"prerelease\": false
            }")
          
          RELEASE_ID=$(echo "$CREATE_RESPONSE" | jq -r '.id')
          
          if [ "$RELEASE_ID" = "null" ] || [ -z "$RELEASE_ID" ]; then
            echo "::error::Failed to create release ${release_tag}"
            {
              echo "- ‚ùå Failed to create release"
              echo "- **Error**: $(echo "$CREATE_RESPONSE" | jq -r '.message // "Unknown error"')"
            } >> "$GITHUB_STEP_SUMMARY"
            exit 1
          fi
          
          echo "‚úÖ Created release ${release_tag} (ID: $RELEASE_ID)"
          echo "- ‚úÖ Release created successfully" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        # Upload asset
        echo "Uploading backup to ${BACKUP_REPO}..."
        UPLOAD_URL="https://uploads.github.com/repos/${BACKUP_REPO}/releases/${RELEASE_ID}/assets?name=${backup_filename}"
        
        UPLOAD_RESPONSE=$(curl -s -X POST \
          -H "Authorization: token $BACKUP_PAT" \
          -H "Content-Type: application/gzip" \
          --data-binary "@${backup_filename}" \
          "$UPLOAD_URL")
        
        ASSET_ID=$(echo "$UPLOAD_RESPONSE" | jq -r '.id')
        
        if [ "$ASSET_ID" = "null" ] || [ -z "$ASSET_ID" ]; then
          echo "::error::Failed to upload backup to ${BACKUP_REPO}"
          {
            echo "- ‚ùå Upload failed"
          } >> "$GITHUB_STEP_SUMMARY"
          echo "upload_success=false" >> "$GITHUB_OUTPUT"
          exit 1
        fi
        
        # Verify upload by checking asset exists
        echo "Verifying uploaded asset..."
        VERIFY_RESPONSE=$(curl -s -H "Authorization: token $BACKUP_PAT" \
          "https://api.github.com/repos/${BACKUP_REPO}/releases/assets/${ASSET_ID}")
        
        VERIFY_ID=$(echo "$VERIFY_RESPONSE" | jq -r '.id')
        VERIFY_SIZE=$(echo "$VERIFY_RESPONSE" | jq -r '.size')
        
        if [ "$VERIFY_ID" != "$ASSET_ID" ]; then
          echo "::error::Upload verification failed - asset not found"
          {
            echo "- ‚ùå Upload verification failed"
          } >> "$GITHUB_STEP_SUMMARY"
          echo "upload_success=false" >> "$GITHUB_OUTPUT"
          exit 1
        fi
        
        # Verify uploaded size matches local size
        local_size="${{ steps.create_backup.outputs.backup_size }}"
        if [ "$VERIFY_SIZE" != "$local_size" ]; then
          echo "::warning::Uploaded size ($VERIFY_SIZE) differs from local size ($local_size)"
          {
            echo "- ‚ö†Ô∏è  Size mismatch: uploaded=$VERIFY_SIZE, local=$local_size"
          } >> "$GITHUB_STEP_SUMMARY"
        fi
        
        echo "‚úÖ Backup uploaded and verified successfully"
        {
          echo "- Backup: \`$backup_filename\`"
          echo "- Repository: \`${BACKUP_REPO}\`"
          echo "- Release: \`${release_tag}\`"
          echo "- Size: \`$(numfmt --to=iec-i --suffix=B ${{ steps.create_backup.outputs.backup_size }})\`"
          echo "- Asset ID: \`${ASSET_ID}\`"
          echo "- Verified: ‚úÖ"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        # Store outputs
        {
          echo "release_tag=$release_tag"
          echo "asset_id=$ASSET_ID"
          echo "upload_success=true"
        } >> "$GITHUB_OUTPUT"
        
        # Cleanup local backup file only after successful upload verification
        rm -f "$backup_filename"

    # Clear GitHub Actions cache after successful backup
    # CRITICAL: GitHub has 10GB limit across ALL caches in repository
    - name: Clear GitHub Actions cache
      if: steps.upload_backup.outputs.upload_success == 'true'
      id: clear_cache
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        {
          echo "**Cache Cleanup:**"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        echo "Clearing ALL GitHub Actions caches (backup is now in permanent storage)..."
        
        # List all caches to get count and size
        CACHE_LIST=$(gh cache list --limit 1000 --json id,key,sizeInBytes 2>&1)
        
        if echo "$CACHE_LIST" | grep -q "no caches found"; then
          echo "No caches to clear"
          {
            echo "- No caches found"
          } >> "$GITHUB_STEP_SUMMARY"
          echo "cache_cleared=true" >> "$GITHUB_OUTPUT"
          echo "caches_deleted=0" >> "$GITHUB_OUTPUT"
          echo "space_freed_mb=0" >> "$GITHUB_OUTPUT"
          exit 0
        fi
        
        # Calculate total size
        TOTAL_SIZE=$(echo "$CACHE_LIST" | jq '[.[].sizeInBytes] | add // 0')
        TOTAL_SIZE_MB=$((TOTAL_SIZE / 1024 / 1024))
        TOTAL_CACHES=$(echo "$CACHE_LIST" | jq 'length')
        
        echo "Found $TOTAL_CACHES cache(s), total size: ${TOTAL_SIZE_MB}MB"
        {
          echo "- Total caches: \`$TOTAL_CACHES\`"
          echo "- Total size: \`${TOTAL_SIZE_MB}MB\`"
        } >> "$GITHUB_STEP_SUMMARY"
        
        # Delete all caches using gh cli (has proper permissions)
        echo "Deleting all caches..."
        gh cache delete --all || {
          echo "::warning::Some caches may have failed to delete"
        }
        
        # Verify deletion
        REMAINING=$(gh cache list --limit 10 --json id 2>&1 | jq 'length // 0' 2>/dev/null || echo "0")
        
        if [ "$REMAINING" -eq 0 ]; then
          {
            echo "- ‚úÖ All caches deleted successfully"
            echo ""
            echo "‚úÖ Cache cleanup completed - freed ${TOTAL_SIZE_MB}MB"
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"
        else
          {
            echo "- ‚ö†Ô∏è  $REMAINING cache(s) remaining (may be in use)"
            echo ""
            echo "‚úÖ Cache cleanup completed - freed ~${TOTAL_SIZE_MB}MB"
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"
        fi
        
        echo "cache_cleared=true" >> "$GITHUB_OUTPUT"
        echo "caches_deleted=$TOTAL_CACHES" >> "$GITHUB_OUTPUT"
        echo "space_freed_mb=$TOTAL_SIZE_MB" >> "$GITHUB_OUTPUT"

    # Apply retention policy (14-day retention, max 10 backups, never delete last backup)
    - name: Apply retention policy
      if: steps.upload_backup.outputs.upload_success == 'true'
      id: retention
      env:
        BACKUP_PAT: ${{ secrets.BACKUP_PAT }}
      run: |
        {
          echo "**Retention Policy:**"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        REPO_OWNER="${{ github.repository_owner }}"
        BACKUP_REPO="${REPO_OWNER}/freesound-backup"
        release_tag="v-checkpoint"
        retention_days=14
        max_count=10
        
        echo "Applying retention policy for $release_tag"
        {
          echo "- Release: \`$release_tag\`"
          echo "- Retention: \`14 days\`"
          echo "- Max Count: \`$max_count\`"
        } >> "$GITHUB_STEP_SUMMARY"
        
        # Get all assets from the release
        ASSETS_JSON=$(curl -s -H "Authorization: token $BACKUP_PAT" \
          "https://api.github.com/repos/${BACKUP_REPO}/releases/tags/${release_tag}")
        
        TOTAL_ASSETS=$(echo "$ASSETS_JSON" | jq '.assets | length')
        echo "- Total backups: \`$TOTAL_ASSETS\`" >> "$GITHUB_STEP_SUMMARY"
        
        # Calculate cutoff date for time-based retention
        CUTOFF_DATE=$(date -u -d "${retention_days} days ago" +%Y-%m-%dT%H:%M:%SZ 2>/dev/null || date -u -v-${retention_days}d +%Y-%m-%dT%H:%M:%S 2>/dev/null || echo "")
        
        if [ -z "$CUTOFF_DATE" ]; then
          echo "::warning::Could not calculate cutoff date, skipping time-based cleanup"
          echo "- ‚ö†Ô∏è  Date calculation failed" >> "$GITHUB_STEP_SUMMARY"
          exit 0
        fi
        
        echo "Cutoff date: $CUTOFF_DATE"
        
        # Get assets older than retention period
        ASSETS_TO_DELETE=$(echo "$ASSETS_JSON" | jq -r ".assets | map(select(.created_at < \"$CUTOFF_DATE\")) | .[].id")
        
        # Count assets to delete
        DELETE_COUNT=$(echo "$ASSETS_TO_DELETE" | grep -c . || echo "0")
        RETAINED_COUNT=$((TOTAL_ASSETS - DELETE_COUNT))
        
        # ATOMIC OPERATION: Ensure at least 1 backup remains at all times
        # New backup was already added, so we need at least 2 total to delete 1
        if [ "$TOTAL_ASSETS" -lt 2 ]; then
          echo "Only $TOTAL_ASSETS backup(s) exist - keeping all"
          {
            echo "- ‚ö†Ô∏è  Keeping all backups (minimum: 1)"
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"
          exit 0
        fi
        
        # Ensure at least 1 backup remains after deletion
        if [ "$RETAINED_COUNT" -lt 1 ]; then
          echo "::warning::Would delete all backups - keeping at least 1"
          echo "- ‚ö†Ô∏è  Keeping at least 1 backup" >> "$GITHUB_STEP_SUMMARY"
          # Remove the newest asset from deletion list (keep most recent)
          ASSETS_TO_DELETE=$(echo "$ASSETS_JSON" | jq -r ".assets | sort_by(.created_at) | .[:-1] | map(select(.created_at < \"$CUTOFF_DATE\")) | .[].id")
          DELETE_COUNT=$(echo "$ASSETS_TO_DELETE" | grep -c . || echo "0")
          RETAINED_COUNT=$((TOTAL_ASSETS - DELETE_COUNT))
        fi
        
        # Also enforce max count limit
        if [ "$TOTAL_ASSETS" -gt "$max_count" ]; then
          TO_DELETE=$((TOTAL_ASSETS - max_count))
          echo "Enforcing max count limit: deleting $TO_DELETE oldest backups..."
          
          OLDEST_ASSETS=$(echo "$ASSETS_JSON" | jq -r ".assets | sort_by(.created_at) | .[:$TO_DELETE] | .[].id")
          
          for ASSET_ID in $OLDEST_ASSETS; do
            # Skip if already in time-based deletion list
            if echo "$ASSETS_TO_DELETE" | grep -q "$ASSET_ID"; then
              continue
            fi
            
            echo "Deleting old asset ID: $ASSET_ID (count limit)"
            DELETE_RESPONSE=$(curl -s -w "%{http_code}" -o /dev/null -X DELETE \
              -H "Authorization: token $BACKUP_PAT" \
              "https://api.github.com/repos/${BACKUP_REPO}/releases/assets/${ASSET_ID}")
            
            if [ "$DELETE_RESPONSE" = "204" ]; then
              DELETED_COUNT=$((DELETED_COUNT + 1))
              echo "  ‚úì Deleted asset $ASSET_ID"
            else
              echo "::warning::Failed to delete asset $ASSET_ID (HTTP $DELETE_RESPONSE)"
              FAILED_DELETIONS=$((FAILED_DELETIONS + 1))
            fi
          done
        fi
        
        # ATOMIC OPERATION: Delete old assets one by one
        # If any deletion fails, we still have the new backup and at least 1 old backup
        DELETED_COUNT=0
        FAILED_DELETIONS=0
        for ASSET_ID in $ASSETS_TO_DELETE; do
          echo "Deleting old backup asset ID: $ASSET_ID"
          DELETE_RESPONSE=$(curl -s -w "%{http_code}" -o /dev/null -X DELETE \
            -H "Authorization: token $BACKUP_PAT" \
            "https://api.github.com/repos/${BACKUP_REPO}/releases/assets/${ASSET_ID}")
          
          if [ "$DELETE_RESPONSE" = "204" ]; then
            DELETED_COUNT=$((DELETED_COUNT + 1))
            echo "  ‚úì Deleted asset $ASSET_ID"
          else
            echo "::warning::Failed to delete asset $ASSET_ID (HTTP $DELETE_RESPONSE)"
            FAILED_DELETIONS=$((FAILED_DELETIONS + 1))
          fi
        done
        
        # Report any failed deletions
        if [ "$FAILED_DELETIONS" -gt 0 ]; then
          echo "- ‚ö†Ô∏è  Failed to delete $FAILED_DELETIONS asset(s)" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        {
          echo "- Backups retained: \`$RETAINED_COUNT\`"
          echo "- Backups deleted: \`$DELETED_COUNT\`"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        echo "‚úÖ Retention policy applied"

    - name: Cleanup on failure
      if: failure()
      run: |
        {
          echo "## ‚ùå Backup Workflow Failed"
          echo ""
          echo "**Rollback Actions:**"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        # Determine which step failed
        if [ "${{ steps.verification.outputs.verification_passed }}" != "true" ]; then
          {
            echo "**Failed Step:** Checkpoint verification"
            echo "**Impact:** No backup created, backup list unchanged"
            echo "**Action:** None required - checkpoint data preserved"
          } >> "$GITHUB_STEP_SUMMARY"
        elif [ "${{ steps.create_backup.outputs.backup_created }}" != "true" ]; then
          {
            echo "**Failed Step:** Backup creation"
            echo "**Impact:** No backup file created, backup list unchanged"
            echo "**Action:** None required - checkpoint data preserved"
          } >> "$GITHUB_STEP_SUMMARY"
        elif [ "${{ steps.verify_backup.outputs.verification_passed }}" != "true" ]; then
          {
            echo "**Failed Step:** Backup verification"
            echo "**Impact:** Backup file created but invalid, backup list unchanged"
            echo "**Action:** Removing invalid backup file"
          } >> "$GITHUB_STEP_SUMMARY"
          
          # Remove invalid backup file
          backup_filename="${{ steps.create_backup.outputs.backup_filename }}"
          if [ -n "$backup_filename" ] && [ -f "$backup_filename" ]; then
            rm -f "$backup_filename"
            echo "- ‚úÖ Removed invalid backup file: \`$backup_filename\`" >> "$GITHUB_STEP_SUMMARY"
          fi
        elif [ "${{ steps.upload_backup.outputs.upload_success }}" != "true" ]; then
          {
            echo "**Failed Step:** Backup upload"
            echo "**Impact:** Backup file created but not uploaded, backup list unchanged"
            echo "**Action:** Removing local backup file"
          } >> "$GITHUB_STEP_SUMMARY"
          
          # Remove local backup file that failed to upload
          backup_filename="${{ steps.create_backup.outputs.backup_filename }}"
          if [ -n "$backup_filename" ] && [ -f "$backup_filename" ]; then
            rm -f "$backup_filename"
            echo "- ‚úÖ Removed local backup file: \`$backup_filename\`" >> "$GITHUB_STEP_SUMMARY"
          fi
        else
          {
            echo "**Failed Step:** Retention policy application"
            echo "**Impact:** New backup uploaded successfully, old backups may not be cleaned up"
            echo "**Action:** None required - new backup is safe, cleanup will retry next run"
          } >> "$GITHUB_STEP_SUMMARY"
        fi
        
        {
          echo ""
          echo "**Critical Guarantee:** Backup list was NOT modified during this failed run."
          echo "All existing backups remain intact and accessible."
          echo ""
          echo "**Next Steps:**"
          echo "1. Review error logs above to identify root cause"
          echo "2. Fix any configuration or permission issues"
          echo "3. Retry backup workflow manually if needed"
          echo "4. Next scheduled run will attempt backup again"
        } >> "$GITHUB_STEP_SUMMARY"

    - name: Generate backup summary
      if: always()
      env:
        BACKUP_PAT: ${{ secrets.BACKUP_PAT }}
      run: |
        # Only generate summary if not already generated by failure handler
        if [ "${{ job.status }}" = "failure" ]; then
          echo "Summary already generated by failure handler"
          exit 0
        fi
        
        {
          echo ""
          echo "---"
          echo ""
          echo "## üìä Backup Summary"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        # Display backup status
        if [ "${{ steps.upload_backup.outputs.upload_success }}" = "true" ]; then
          {
            echo "### ‚úÖ Backup Successful"
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"
          
          reason="${{ steps.backup_reason.outputs.reason }}"
          
          # Highlight failure recovery
          if [ "$reason" = "failure_recovery" ]; then
            {
              echo "**‚ö†Ô∏è  Failure Recovery Backup**"
              echo ""
              echo "This backup preserves partial progress from a failed collection run."
              echo "The checkpoint contains ${{ steps.verification.outputs.node_count }} samples that were successfully collected before the failure."
              echo ""
            } >> "$GITHUB_STEP_SUMMARY"
          fi
          
          {
            echo "**Backup Details:**"
            echo "- Filename: \`${{ steps.create_backup.outputs.backup_filename }}\`"
            echo "- Size: \`$(numfmt --to=iec-i --suffix=B ${{ steps.create_backup.outputs.backup_size }})\`"
            echo "- Samples: \`${{ steps.verification.outputs.node_count }}\`"
            echo "- Edges: \`${{ steps.verification.outputs.edge_count }}\`"
            echo "- Release: \`v-checkpoint\`"
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"
          
          # Cache cleanup status
          if [ "${{ steps.clear_cache.outputs.cache_cleared }}" = "true" ]; then
            {
              echo "**Cache Cleanup:**"
              echo "- Caches deleted: \`${{ steps.clear_cache.outputs.caches_deleted }}\`"
              echo "- Space freed: \`${{ steps.clear_cache.outputs.space_freed_mb }}MB\`"
              echo "- Status: ‚úÖ All caches cleared (backup in permanent storage)"
              echo ""
            } >> "$GITHUB_STEP_SUMMARY"
          fi
        else
          {
            echo "### ‚ùå Backup Failed"
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"
          
          if [ "${{ steps.verification.outputs.verification_passed }}" != "true" ]; then
            echo "**Reason:** Checkpoint verification failed" >> "$GITHUB_STEP_SUMMARY"
          elif [ "${{ steps.create_backup.outputs.backup_created }}" != "true" ]; then
            echo "**Reason:** Backup creation failed" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "**Reason:** Backup upload failed" >> "$GITHUB_STEP_SUMMARY"
          fi
          echo "" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        # Display backup list status per tier
        if [ -n "$BACKUP_PAT" ]; then
          {
            echo "**Backup Repository Status:**"
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"
          
          REPO_OWNER="${{ github.repository_owner }}"
          BACKUP_REPO="${REPO_OWNER}/freesound-backup"
          
          # Check v-checkpoint release
          ASSETS_JSON=$(curl -s -H "Authorization: token $BACKUP_PAT" \
            "https://api.github.com/repos/${BACKUP_REPO}/releases/tags/v-checkpoint")
          
          if ! echo "$ASSETS_JSON" | grep -q "Not Found"; then
            ASSET_COUNT=$(echo "$ASSETS_JSON" | jq '.assets | length')
            
            if [ "$ASSET_COUNT" -gt 0 ]; then
              # Get oldest asset age
              OLDEST_DATE=$(echo "$ASSETS_JSON" | jq -r '.assets | sort_by(.created_at) | .[0].created_at')
              OLDEST_AGE=$(( ($(date +%s) - $(date -d "$OLDEST_DATE" +%s 2>/dev/null || date -j -f "%Y-%m-%dT%H:%M:%SZ" "$OLDEST_DATE" +%s 2>/dev/null || echo "0")) / 86400 ))
              
              echo "- **v-checkpoint**: $ASSET_COUNT backups (oldest: ${OLDEST_AGE}d, retention: 14 days)" >> "$GITHUB_STEP_SUMMARY"
            fi
          fi
          
          echo "" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        {
          echo "**Retention Policy:**"
          echo "- \`v-checkpoint\`: 14 days (max 10 backups, never delete last backup)"
        } >> "$GITHUB_STEP_SUMMARY"

  # Job to explicitly notify when backup is skipped
  # This job FAILS to make the workflow status reflect the skip
  backup-skipped:
    name: Backup Skipped - Workflow Failed
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: check-trigger
    if: needs.check-trigger.outputs.should_backup != 'true'
    steps:
    - name: Log skip reason and fail
      run: |
        {
          echo "## ‚ùå Backup Skipped - Workflow Failed"
          echo ""
          echo "**Reason:** ${{ needs.check-trigger.outputs.skip_reason }}"
          echo ""
          echo "**Trigger Details:**"
          echo "- Event: \`${{ github.event_name }}\`"
          echo "- Workflow: \`${{ needs.check-trigger.outputs.trigger_workflow }}\`"
          echo "- Conclusion: \`${{ github.event.workflow_run.conclusion }}\`"
          echo ""
          echo "**Expected Behavior:**"
          echo "- Validation workflows only trigger backup on success"
          echo "- Collection and repair workflows always trigger backup (for recovery)"
          echo "- Manual and scheduled runs always trigger backup"
          echo ""
          echo "**This workflow is marked as FAILED to indicate backup was skipped.**"
        } >> "$GITHUB_STEP_SUMMARY"
        
        echo "‚ùå Backup skipped: ${{ needs.check-trigger.outputs.skip_reason }}"
        echo "::error::Backup was skipped - ${{ needs.check-trigger.outputs.skip_reason }}"
        exit 1
