# Freesound Backup Workflow
#
# Triggered automatically after collection or validation pipelines complete.
# This workflow creates and manages backups of checkpoint data with tier-specific
# retention policies and failure recovery support.
#
# Architecture:
# - Triggered by: Collection Pipeline (on completion - success OR failure)
# - Triggered by: Validation Pipeline (on success only)
# - Scheduled: Every 6 hours for periodic backups
# - Restores checkpoint from GitHub Actions cache (triggered runs only)
# - Creates compressed backup with tier tagging
# - Uploads to PRIMARY backup repository ONLY
# - Applies tier-specific retention policies
# - Supports failure recovery to preserve partial progress
#
# Backup Tiers:
# - recovery: Failure recovery backups (7-day retention)
# - validated: Validated checkpoints (30-day retention)
# - checkpoint: Frequent backups from collection pipeline (14-day retention)
# - permanent: Milestone backups from collection pipeline (unlimited retention)
#
# Features:
# - Failure recovery: Preserves partial progress when collection fails
# - Atomic operations: Only updates backup list after successful upload
# - Tier-specific retention: Different policies for different backup types
# - Cache-based checkpoint sharing (no repo cloning needed)
# - Comprehensive logging and monitoring
#
# CRITICAL: Only interacts with PRIMARY backup repo (no BACKUP_PAT_SECONDARY)

name: Freesound Backup

on:
  workflow_run:
    workflows: 
      - "Freesound Nightly Collection"
      - "Freesound Validation & Visualization"
    types: [completed]
    branches: [main]
  
  schedule:
    # Run every 6 hours for periodic backups
    - cron: '0 */6 * * *'
  
  workflow_dispatch:
    # Allow manual triggering for testing

# Prevent workflow collisions
concurrency:
  group: freesound-backup
  cancel-in-progress: false

jobs:
  backup-checkpoint:
    name: Create and Manage Checkpoint Backup
    runs-on: ubuntu-latest
    timeout-minutes: 30
    # Only run if:
    # - Manual trigger (workflow_dispatch)
    # - Scheduled run
    # - Collection pipeline completed (success or failure - for failure recovery)
    # - Validation pipeline succeeded (NOT on failure)
    if: |
      github.event_name == 'workflow_dispatch' ||
      github.event_name == 'schedule' ||
      (github.event.workflow_run.name == 'Freesound Nightly Collection') ||
      (github.event.workflow_run.name == 'Freesound Validation & Visualization' && github.event.workflow_run.conclusion == 'success')
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 1
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: 'FollowWeb/requirements.txt'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install jq
    
    - name: Set execution parameters
      id: params
      run: |
        {
          echo "execution_id=$(date +'%Y%m%d_%H%M%S')"
          echo "timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")"
        } >> "$GITHUB_OUTPUT"
    
    # Subtask 11.1: Implement failure detection and cache restore
    - name: Detect backup reason and determine cache strategy
      id: backup_reason
      run: |
        {
          echo "## ðŸ’¾ Backup Workflow"
          echo ""
          echo "**Configuration:**"
          echo "- Execution ID: \`${{ steps.params.outputs.execution_id }}\`"
          echo "- Trigger: \`${{ github.event_name }}\`"
        } >> "$GITHUB_STEP_SUMMARY"
        
        # Determine backup reason based on trigger
        if [ "${{ github.event_name }}" = "schedule" ]; then
          {
            echo "reason=scheduled"
            echo "use_cache=false"
            echo "tier=scheduled"
          } >> "$GITHUB_OUTPUT"
          {
            echo "- Backup Reason: \`Scheduled (periodic backup)\`"
            echo "- Source: Repository checkpoint"
          } >> "$GITHUB_STEP_SUMMARY"
        elif [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          {
            echo "reason=manual"
            echo "use_cache=false"
            echo "tier=manual"
          } >> "$GITHUB_OUTPUT"
          {
            echo "- Backup Reason: \`Manual trigger\`"
            echo "- Source: Repository checkpoint"
          } >> "$GITHUB_STEP_SUMMARY"
        else
          # Triggered by upstream workflow
          upstream_workflow="${{ github.event.workflow_run.name }}"
          upstream_conclusion="${{ github.event.workflow_run.conclusion }}"
          
          {
            echo "- Upstream Workflow: \`$upstream_workflow\`"
            echo "- Upstream Conclusion: \`$upstream_conclusion\`"
            echo "- Upstream Run: [#${{ github.event.workflow_run.run_number }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.event.workflow_run.id }})"
          } >> "$GITHUB_STEP_SUMMARY"
          
          # Determine reason based on upstream workflow and conclusion
          if [ "$upstream_workflow" = "Freesound Nightly Pipeline" ]; then
            if [ "$upstream_conclusion" = "success" ]; then
              {
                echo "reason=collection_success"
                echo "tier=checkpoint"
              } >> "$GITHUB_OUTPUT"
              echo "- Backup Reason: \`Collection pipeline succeeded\`" >> "$GITHUB_STEP_SUMMARY"
            else
              {
                echo "reason=failure_recovery"
                echo "tier=recovery"
              } >> "$GITHUB_OUTPUT"
              echo "- Backup Reason: \`âš ï¸  Failure Recovery (preserving partial progress)\`" >> "$GITHUB_STEP_SUMMARY"
            fi
            {
              echo "use_cache=true"
              echo "cache_key=checkpoint-${{ github.event.workflow_run.id }}"
            } >> "$GITHUB_OUTPUT"
            echo "- Cache Key: \`checkpoint-${{ github.event.workflow_run.id }}\`" >> "$GITHUB_STEP_SUMMARY"
          elif [ "$upstream_workflow" = "Freesound Validation & Visualization" ]; then
            {
              echo "reason=validation_success"
              echo "tier=validated"
              echo "use_cache=true"
              echo "cache_key=checkpoint-${{ github.event.workflow_run.id }}"
            } >> "$GITHUB_OUTPUT"
            {
              echo "- Backup Reason: \`Validation pipeline succeeded\`"
              echo "- Cache Key: \`checkpoint-${{ github.event.workflow_run.id }}\`"
            } >> "$GITHUB_STEP_SUMMARY"
          else
            {
              echo "reason=unknown"
              echo "tier=unknown"
              echo "use_cache=false"
            } >> "$GITHUB_OUTPUT"
            echo "- Backup Reason: \`Unknown trigger\`" >> "$GITHUB_STEP_SUMMARY"
          fi
        fi
        
        echo "" >> "$GITHUB_STEP_SUMMARY"

    - name: Restore checkpoint from cache
      if: steps.backup_reason.outputs.use_cache == 'true'
      uses: actions/cache/restore@v3
      id: cache-restore
      with:
        path: data/freesound_library
        key: ${{ steps.backup_reason.outputs.cache_key }}
        # Note: Cache restore works even if upstream workflow failed
        # because cache is saved with if: always() condition
    
    - name: Download checkpoint from repository (scheduled/manual runs)
      if: steps.backup_reason.outputs.use_cache == 'false'
      env:
        BACKUP_PAT: ${{ secrets.BACKUP_PAT }}
      run: |
        echo "Downloading checkpoint from private repository..."
        
        # Check if BACKUP_PAT is configured
        if [ -z "$BACKUP_PAT" ]; then
          echo "::error::BACKUP_PAT not configured - cannot download checkpoint"
          echo "âŒ BACKUP_PAT required" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        REPO_OWNER="${{ github.repository_owner }}"
        BACKUP_REPO="${REPO_OWNER}/freesound-backup"
        
        # Get latest checkpoint from v-checkpoint release
        ASSETS_JSON=$(curl -s -H "Authorization: token $BACKUP_PAT" \
          "https://api.github.com/repos/${BACKUP_REPO}/releases/tags/v-checkpoint")
        
        if echo "$ASSETS_JSON" | grep -q "Not Found"; then
          echo "::warning::No checkpoint available in backup repository"
          echo "âš ï¸  No checkpoint available" >> "$GITHUB_STEP_SUMMARY"
          exit 0
        fi
        
        # Find most recent checkpoint
        LATEST_ASSET=$(echo "$ASSETS_JSON" | jq -r '.assets | sort_by(.created_at) | reverse | .[0]')
        
        if [ "$LATEST_ASSET" = "null" ] || [ -z "$LATEST_ASSET" ]; then
          echo "::warning::No checkpoint backups found"
          echo "âš ï¸  No backups found" >> "$GITHUB_STEP_SUMMARY"
          exit 0
        fi
        
        ASSET_NAME=$(echo "$LATEST_ASSET" | jq -r '.name')
        ASSET_URL=$(echo "$LATEST_ASSET" | jq -r '.url')
        
        echo "Downloading: $ASSET_NAME"
        curl -L -H "Authorization: token $BACKUP_PAT" \
          -H "Accept: application/octet-stream" \
          "$ASSET_URL" -o checkpoint_backup.tar.gz
        
        # Extract checkpoint
        mkdir -p data/freesound_library
        tar -xzf checkpoint_backup.tar.gz -C data/
        rm -f checkpoint_backup.tar.gz
        
        echo "âœ… Checkpoint downloaded from repository"

    # Subtask 11.2: Implement checkpoint integrity verification
    - name: Verify checkpoint integrity
      id: verification
      run: |
        echo "**Checkpoint Verification:**" >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"
        
        # Check if checkpoint directory exists
        if [ ! -d "data/freesound_library" ]; then
          echo "::error::Checkpoint directory not found"
          echo "- âŒ Directory not found" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        CHECKPOINT_DIR="data/freesound_library"
        
        # Check required files exist
        missing_files=0
        
        if [ ! -f "$CHECKPOINT_DIR/graph_topology.gpickle" ]; then
          echo "::error::Missing graph_topology.gpickle"
          echo "- âŒ Missing: graph_topology.gpickle" >> "$GITHUB_STEP_SUMMARY"
          missing_files=$((missing_files + 1))
        else
          graph_size=$(stat -f%z "$CHECKPOINT_DIR/graph_topology.gpickle" 2>/dev/null || stat -c%s "$CHECKPOINT_DIR/graph_topology.gpickle")
          echo "- âœ… graph_topology.gpickle ($(numfmt --to=iec-i --suffix=B "$graph_size"))" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        if [ ! -f "$CHECKPOINT_DIR/metadata_cache.db" ]; then
          echo "::error::Missing metadata_cache.db"
          echo "- âŒ Missing: metadata_cache.db" >> "$GITHUB_STEP_SUMMARY"
          missing_files=$((missing_files + 1))
        else
          db_size=$(stat -f%z "$CHECKPOINT_DIR/metadata_cache.db" 2>/dev/null || stat -c%s "$CHECKPOINT_DIR/metadata_cache.db")
          echo "- âœ… metadata_cache.db ($(numfmt --to=iec-i --suffix=B "$db_size"))" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        if [ ! -f "$CHECKPOINT_DIR/checkpoint_metadata.json" ]; then
          echo "::warning::Missing checkpoint_metadata.json"
          echo "- âš ï¸  Missing: checkpoint_metadata.json" >> "$GITHUB_STEP_SUMMARY"
        else
          meta_size=$(stat -f%z "$CHECKPOINT_DIR/checkpoint_metadata.json" 2>/dev/null || stat -c%s "$CHECKPOINT_DIR/checkpoint_metadata.json")
          echo "- âœ… checkpoint_metadata.json ($(numfmt --to=iec-i --suffix=B "$meta_size"))" >> "$GITHUB_STEP_SUMMARY"
          
          # Extract node count from metadata
          node_count=$(jq -r '.total_nodes // 0' "$CHECKPOINT_DIR/checkpoint_metadata.json")
          edge_count=$(jq -r '.total_edges // 0' "$CHECKPOINT_DIR/checkpoint_metadata.json")
          {
            echo "node_count=$node_count"
            echo "edge_count=$edge_count"
          } >> "$GITHUB_OUTPUT"
          {
            echo "- Nodes: \`$node_count\`"
            echo "- Edges: \`$edge_count\`"
          } >> "$GITHUB_STEP_SUMMARY"
        fi
        
        if [ "$missing_files" -gt 0 ]; then
          echo "::error::Checkpoint verification failed - missing critical files"
          exit 1
        fi
        
        # Verify file sizes are reasonable (> 1KB for graph, > 10KB for db)
        if [ "$graph_size" -lt 1024 ]; then
          echo "::error::Graph file too small: $graph_size bytes"
          echo "- âŒ Graph file too small" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        if [ "$db_size" -lt 10240 ]; then
          echo "::error::Database file too small: $db_size bytes"
          echo "- âŒ Database file too small" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        echo "verification_passed=true" >> "$GITHUB_OUTPUT"
        {
          echo ""
          echo "âœ… Checkpoint verification passed"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"

    # Subtask 11.3: Implement backup creation with tier tagging
    - name: Create backup archive with tier tagging
      if: steps.verification.outputs.verification_passed == 'true'
      id: create_backup
      run: |
        echo "**Backup Creation:**" >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"
        
        # Get backup tier and reason
        tier="${{ steps.backup_reason.outputs.tier }}"
        reason="${{ steps.backup_reason.outputs.reason }}"
        node_count="${{ steps.verification.outputs.node_count }}"
        edge_count="${{ steps.verification.outputs.edge_count }}"
        
        # Create backup filename with tier information
        backup_filename="checkpoint_backup_${node_count}nodes_${tier}_${{ github.run_id }}.tar.gz"
        
        echo "Creating backup archive: $backup_filename"
        echo "- Tier: $tier"
        echo "- Reason: $reason"
        
        # Create compressed archive
        tar -czf "$backup_filename" -C data freesound_library/
        
        # Get file size
        backup_size=$(stat -f%z "$backup_filename" 2>/dev/null || stat -c%s "$backup_filename")
        echo "Backup size: $(numfmt --to=iec-i --suffix=B "$backup_size")"
        
        # Create backup metadata JSON
        cat > backup_metadata.json << EOF
        {
          "timestamp": "${{ steps.params.outputs.timestamp }}",
          "run_id": "${{ github.run_id }}",
          "samples": ${node_count},
          "edges": ${edge_count},
          "validation_status": "$([ "$reason" = "validation_success" ] && echo "passed" || echo "unknown")",
          "backup_reason": "$reason",
          "tier": "$tier",
          "file_size_bytes": ${backup_size},
          "workflow_trigger": "${{ github.event_name }}"
        EOF
        
        # Add failure metadata for recovery backups
        if [ "$reason" = "failure_recovery" ]; then
          jq '. + {
            "failed_workflow_run": "${{ github.event.workflow_run.id }}",
            "samples_preserved": ${node_count},
            "recovery_backup": true
          }' backup_metadata.json > backup_metadata_tmp.json
          mv backup_metadata_tmp.json backup_metadata.json
        fi
        
        # Display metadata
        {
          echo "Backup metadata:"
          echo "\`\`\`json"
          cat backup_metadata.json
          echo "\`\`\`"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        # Store outputs
        {
          echo "backup_filename=$backup_filename"
          echo "backup_size=$backup_size"
          echo "backup_created=true"
        } >> "$GITHUB_OUTPUT"

    # Subtask 19.1: Implement backup verification
    - name: Verify backup file integrity
      if: steps.create_backup.outputs.backup_created == 'true'
      id: verify_backup
      run: |
        echo "**Backup Verification:**" >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"
        
        backup_filename="${{ steps.create_backup.outputs.backup_filename }}"
        
        # Check if backup file exists
        if [ ! -f "$backup_filename" ]; then
          echo "::error::Backup file not found: $backup_filename"
          echo "- âŒ Backup file not found" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        # Check file size is reasonable (> 100KB, < 10GB)
        backup_size=$(stat -f%z "$backup_filename" 2>/dev/null || stat -c%s "$backup_filename")
        min_size=102400  # 100KB
        max_size=10737418240  # 10GB
        
        if [ "$backup_size" -lt "$min_size" ]; then
          echo "::error::Backup file too small: $(numfmt --to=iec-i --suffix=B "$backup_size") (minimum: 100KB)"
          echo "- âŒ Backup file too small: $(numfmt --to=iec-i --suffix=B "$backup_size")" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        if [ "$backup_size" -gt "$max_size" ]; then
          echo "::error::Backup file too large: $(numfmt --to=iec-i --suffix=B "$backup_size") (maximum: 10GB)"
          echo "- âŒ Backup file too large: $(numfmt --to=iec-i --suffix=B "$backup_size")" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        echo "- âœ… File size valid: $(numfmt --to=iec-i --suffix=B "$backup_size")" >> "$GITHUB_STEP_SUMMARY"
        
        # Verify archive integrity (can be extracted)
        echo "Verifying archive can be extracted..."
        if tar -tzf "$backup_filename" > /dev/null 2>&1; then
          echo "- âœ… Archive integrity verified" >> "$GITHUB_STEP_SUMMARY"
        else
          echo "::error::Archive is corrupted or cannot be extracted"
          echo "- âŒ Archive corrupted" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        # Verify required files are in archive
        echo "Verifying required files in archive..."
        required_files=(
          "freesound_library/graph_topology.gpickle"
          "freesound_library/metadata_cache.db"
          "freesound_library/checkpoint_metadata.json"
        )
        
        missing_files=0
        for file in "${required_files[@]}"; do
          if tar -tzf "$backup_filename" "$file" > /dev/null 2>&1; then
            echo "  âœ“ $file"
          else
            echo "::error::Missing required file in archive: $file"
            echo "- âŒ Missing: $file" >> "$GITHUB_STEP_SUMMARY"
            missing_files=$((missing_files + 1))
          fi
        done
        
        if [ "$missing_files" -gt 0 ]; then
          echo "::error::Archive missing $missing_files required files"
          exit 1
        fi
        
        echo "- âœ… All required files present" >> "$GITHUB_STEP_SUMMARY"
        
        # Test extraction to temporary directory
        echo "Testing extraction..."
        test_dir=$(mktemp -d)
        if tar -xzf "$backup_filename" -C "$test_dir" > /dev/null 2>&1; then
          echo "- âœ… Test extraction successful" >> "$GITHUB_STEP_SUMMARY"
          rm -rf "$test_dir"
        else
          echo "::error::Failed to extract archive to test directory"
          echo "- âŒ Test extraction failed" >> "$GITHUB_STEP_SUMMARY"
          rm -rf "$test_dir"
          exit 1
        fi
        
        echo "" >> "$GITHUB_STEP_SUMMARY"
        echo "âœ… Backup verification passed" >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"
        
        echo "verification_passed=true" >> "$GITHUB_OUTPUT"

    # Subtask 11.4: Implement backup upload with tier-specific releases
    - name: Upload backup to PRIMARY repository
      if: steps.verify_backup.outputs.verification_passed == 'true'
      id: upload_backup
      env:
        BACKUP_PAT: ${{ secrets.BACKUP_PAT }}
      run: |
        echo "**Backup Upload:**" >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"
        
        # Check if BACKUP_PAT is configured (required)
        if [ -z "$BACKUP_PAT" ]; then
          echo "::error::BACKUP_PAT not configured - cannot upload backup"
          echo "- âŒ BACKUP_PAT not configured (CRITICAL)" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        backup_filename="${{ steps.create_backup.outputs.backup_filename }}"
        tier="${{ steps.backup_reason.outputs.tier }}"
        reason="${{ steps.backup_reason.outputs.reason }}"
        
        # Map tier to release tag
        case "$tier" in
          recovery)
            release_tag="v-recovery"
            ;;
          validated)
            release_tag="v-validated"
            ;;
          checkpoint|collection_success)
            release_tag="v-checkpoint"
            ;;
          scheduled|manual)
            release_tag="v-checkpoint"
            ;;
          *)
            echo "::error::Unknown tier: $tier"
            exit 1
            ;;
        esac
        
        echo "Uploading to release: $release_tag"
        echo "- Release Tag: \`$release_tag\`" >> "$GITHUB_STEP_SUMMARY"
        
        REPO_OWNER="${{ github.repository_owner }}"
        BACKUP_REPO="${REPO_OWNER}/freesound-backup"
        
        # Get release ID for the appropriate tag
        RELEASE_JSON=$(curl -s -H "Authorization: token $BACKUP_PAT" \
          "https://api.github.com/repos/${BACKUP_REPO}/releases/tags/${release_tag}")
        
        RELEASE_ID=$(echo "$RELEASE_JSON" | jq -r '.id')
        
        if [ "$RELEASE_ID" = "null" ] || [ -z "$RELEASE_ID" ]; then
          echo "::error::Release ${release_tag} not found in ${BACKUP_REPO}"
          echo "- âŒ Release not found: \`${release_tag}\`" >> "$GITHUB_STEP_SUMMARY"
          echo "- **Action Required**: Create release '${release_tag}' in ${BACKUP_REPO}" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        # Upload asset
        echo "Uploading backup to ${BACKUP_REPO}..."
        UPLOAD_URL="https://uploads.github.com/repos/${BACKUP_REPO}/releases/${RELEASE_ID}/assets?name=${backup_filename}"
        
        UPLOAD_RESPONSE=$(curl -s -X POST \
          -H "Authorization: token $BACKUP_PAT" \
          -H "Content-Type: application/gzip" \
          --data-binary "@${backup_filename}" \
          "$UPLOAD_URL")
        
        ASSET_ID=$(echo "$UPLOAD_RESPONSE" | jq -r '.id')
        
        if [ "$ASSET_ID" = "null" ] || [ -z "$ASSET_ID" ]; then
          echo "::error::Failed to upload backup to ${BACKUP_REPO}"
          echo "- âŒ Upload failed" >> "$GITHUB_STEP_SUMMARY"
          echo "upload_success=false" >> "$GITHUB_OUTPUT"
          exit 1
        fi
        
        # Verify upload by checking asset exists
        echo "Verifying uploaded asset..."
        VERIFY_RESPONSE=$(curl -s -H "Authorization: token $BACKUP_PAT" \
          "https://api.github.com/repos/${BACKUP_REPO}/releases/assets/${ASSET_ID}")
        
        VERIFY_ID=$(echo "$VERIFY_RESPONSE" | jq -r '.id')
        VERIFY_SIZE=$(echo "$VERIFY_RESPONSE" | jq -r '.size')
        
        if [ "$VERIFY_ID" != "$ASSET_ID" ]; then
          echo "::error::Upload verification failed - asset not found"
          echo "- âŒ Upload verification failed" >> "$GITHUB_STEP_SUMMARY"
          echo "upload_success=false" >> "$GITHUB_OUTPUT"
          exit 1
        fi
        
        # Verify uploaded size matches local size
        local_size="${{ steps.create_backup.outputs.backup_size }}"
        if [ "$VERIFY_SIZE" != "$local_size" ]; then
          echo "::warning::Uploaded size ($VERIFY_SIZE) differs from local size ($local_size)"
          echo "- âš ï¸  Size mismatch: uploaded=$VERIFY_SIZE, local=$local_size" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        echo "âœ… Backup uploaded and verified successfully"
        echo "- Backup: \`$backup_filename\`" >> "$GITHUB_STEP_SUMMARY"
        echo "- Repository: \`${BACKUP_REPO}\`" >> "$GITHUB_STEP_SUMMARY"
        echo "- Release: \`${release_tag}\`" >> "$GITHUB_STEP_SUMMARY"
        echo "- Size: \`$(numfmt --to=iec-i --suffix=B ${{ steps.create_backup.outputs.backup_size }})\`" >> "$GITHUB_STEP_SUMMARY"
        echo "- Asset ID: \`${ASSET_ID}\`" >> "$GITHUB_STEP_SUMMARY"
        echo "- Verified: âœ…" >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"
        
        # Store outputs
        echo "release_tag=$release_tag" >> "$GITHUB_OUTPUT"
        echo "asset_id=$ASSET_ID" >> "$GITHUB_OUTPUT"
        echo "upload_success=true" >> "$GITHUB_OUTPUT"
        
        # Cleanup local backup file only after successful upload verification
        rm -f "$backup_filename"

    # Subtask 11.5: Implement atomic backup list update with tier-specific retention
    - name: Apply tier-specific retention policies
      if: steps.upload_backup.outputs.upload_success == 'true'
      id: retention
      env:
        BACKUP_PAT: ${{ secrets.BACKUP_PAT }}
      run: |
        echo "**Retention Policy:**" >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"
        
        REPO_OWNER="${{ github.repository_owner }}"
        BACKUP_REPO="${REPO_OWNER}/freesound-backup"
        release_tag="${{ steps.upload_backup.outputs.release_tag }}"
        
        # Define retention policies by tier
        case "$release_tag" in
          v-recovery)
            retention_days=7
            retention_label="7 days"
            ;;
          v-validated)
            retention_days=30
            retention_label="30 days"
            ;;
          v-checkpoint)
            retention_days=14
            retention_label="14 days"
            ;;
          v-permanent)
            retention_days=0  # Unlimited
            retention_label="Unlimited (permanent)"
            ;;
          *)
            retention_days=14
            retention_label="14 days (default)"
            ;;
        esac
        
        echo "Applying retention policy for $release_tag: $retention_label"
        echo "- Release: \`$release_tag\`" >> "$GITHUB_STEP_SUMMARY"
        echo "- Retention: \`$retention_label\`" >> "$GITHUB_STEP_SUMMARY"
        
        # Get all assets from the release
        ASSETS_JSON=$(curl -s -H "Authorization: token $BACKUP_PAT" \
          "https://api.github.com/repos/${BACKUP_REPO}/releases/tags/${release_tag}")
        
        TOTAL_ASSETS=$(echo "$ASSETS_JSON" | jq '.assets | length')
        echo "- Total backups: \`$TOTAL_ASSETS\`" >> "$GITHUB_STEP_SUMMARY"
        
        # Skip retention for permanent tier
        if [ "$release_tag" = "v-permanent" ]; then
          echo "- Action: No cleanup (permanent tier)" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          exit 0
        fi
        
        # Calculate cutoff date for time-based retention
        CUTOFF_DATE=$(date -u -d "${retention_days} days ago" +%Y-%m-%dT%H:%M:%SZ 2>/dev/null || date -u -v-${retention_days}d +%Y-%m-%dT%H:%M:%S 2>/dev/null || echo "")
        
        if [ -z "$CUTOFF_DATE" ]; then
          echo "::warning::Could not calculate cutoff date, skipping time-based cleanup"
          echo "- âš ï¸  Date calculation failed" >> "$GITHUB_STEP_SUMMARY"
          exit 0
        fi
        
        echo "Cutoff date: $CUTOFF_DATE"
        
        # Get assets older than retention period
        ASSETS_TO_DELETE=$(echo "$ASSETS_JSON" | jq -r ".assets | map(select(.created_at < \"$CUTOFF_DATE\")) | .[].id")
        
        # Count assets to delete
        DELETE_COUNT=$(echo "$ASSETS_TO_DELETE" | grep -c . || echo "0")
        RETAINED_COUNT=$((TOTAL_ASSETS - DELETE_COUNT))
        
        # ATOMIC OPERATION: Ensure at least 1 backup remains at all times
        # New backup was already added, so we need at least 2 total to delete 1
        if [ "$TOTAL_ASSETS" -lt 2 ]; then
          echo "Only $TOTAL_ASSETS backup(s) exist - keeping all"
          echo "- âš ï¸  Keeping all backups (minimum: 1)" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          exit 0
        fi
        
        # Ensure at least 1 backup remains after deletion
        if [ "$RETAINED_COUNT" -lt 1 ]; then
          echo "::warning::Would delete all backups - keeping at least 1"
          echo "- âš ï¸  Keeping at least 1 backup" >> "$GITHUB_STEP_SUMMARY"
          # Remove the newest asset from deletion list (keep most recent)
          ASSETS_TO_DELETE=$(echo "$ASSETS_JSON" | jq -r ".assets | sort_by(.created_at) | .[:-1] | map(select(.created_at < \"$CUTOFF_DATE\")) | .[].id")
          DELETE_COUNT=$(echo "$ASSETS_TO_DELETE" | grep -c . || echo "0")
          RETAINED_COUNT=$((TOTAL_ASSETS - DELETE_COUNT))
        fi
        
        # ATOMIC OPERATION: Delete old assets one by one
        # If any deletion fails, we still have the new backup and at least 1 old backup
        DELETED_COUNT=0
        FAILED_DELETIONS=0
        for ASSET_ID in $ASSETS_TO_DELETE; do
          echo "Deleting old backup asset ID: $ASSET_ID"
          DELETE_RESPONSE=$(curl -s -w "%{http_code}" -o /dev/null -X DELETE \
            -H "Authorization: token $BACKUP_PAT" \
            "https://api.github.com/repos/${BACKUP_REPO}/releases/assets/${ASSET_ID}")
          
          if [ "$DELETE_RESPONSE" = "204" ]; then
            DELETED_COUNT=$((DELETED_COUNT + 1))
            echo "  âœ“ Deleted asset $ASSET_ID"
          else
            echo "::warning::Failed to delete asset $ASSET_ID (HTTP $DELETE_RESPONSE)"
            FAILED_DELETIONS=$((FAILED_DELETIONS + 1))
          fi
        done
        
        # Report any failed deletions
        if [ "$FAILED_DELETIONS" -gt 0 ]; then
          echo "- âš ï¸  Failed to delete $FAILED_DELETIONS asset(s)" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        echo "- Backups retained: \`$RETAINED_COUNT\`" >> "$GITHUB_STEP_SUMMARY"
        echo "- Backups deleted: \`$DELETED_COUNT\`" >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"
        
        echo "âœ… Retention policy applied"

    # Subtask 19.3: Implement rollback on failure
    - name: Cleanup on failure
      if: failure()
      run: |
        echo "## âŒ Backup Workflow Failed" >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"
        echo "**Rollback Actions:**" >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"
        
        # Determine which step failed
        if [ "${{ steps.verification.outputs.verification_passed }}" != "true" ]; then
          echo "**Failed Step:** Checkpoint verification" >> "$GITHUB_STEP_SUMMARY"
          echo "**Impact:** No backup created, backup list unchanged" >> "$GITHUB_STEP_SUMMARY"
          echo "**Action:** None required - checkpoint data preserved" >> "$GITHUB_STEP_SUMMARY"
        elif [ "${{ steps.create_backup.outputs.backup_created }}" != "true" ]; then
          echo "**Failed Step:** Backup creation" >> "$GITHUB_STEP_SUMMARY"
          echo "**Impact:** No backup file created, backup list unchanged" >> "$GITHUB_STEP_SUMMARY"
          echo "**Action:** None required - checkpoint data preserved" >> "$GITHUB_STEP_SUMMARY"
        elif [ "${{ steps.verify_backup.outputs.verification_passed }}" != "true" ]; then
          echo "**Failed Step:** Backup verification" >> "$GITHUB_STEP_SUMMARY"
          echo "**Impact:** Backup file created but invalid, backup list unchanged" >> "$GITHUB_STEP_SUMMARY"
          echo "**Action:** Removing invalid backup file" >> "$GITHUB_STEP_SUMMARY"
          
          # Remove invalid backup file
          backup_filename="${{ steps.create_backup.outputs.backup_filename }}"
          if [ -n "$backup_filename" ] && [ -f "$backup_filename" ]; then
            rm -f "$backup_filename"
            echo "- âœ… Removed invalid backup file: \`$backup_filename\`" >> "$GITHUB_STEP_SUMMARY"
          fi
        elif [ "${{ steps.upload_backup.outputs.upload_success }}" != "true" ]; then
          echo "**Failed Step:** Backup upload" >> "$GITHUB_STEP_SUMMARY"
          echo "**Impact:** Backup file created but not uploaded, backup list unchanged" >> "$GITHUB_STEP_SUMMARY"
          echo "**Action:** Removing local backup file" >> "$GITHUB_STEP_SUMMARY"
          
          # Remove local backup file that failed to upload
          backup_filename="${{ steps.create_backup.outputs.backup_filename }}"
          if [ -n "$backup_filename" ] && [ -f "$backup_filename" ]; then
            rm -f "$backup_filename"
            echo "- âœ… Removed local backup file: \`$backup_filename\`" >> "$GITHUB_STEP_SUMMARY"
          fi
        else
          echo "**Failed Step:** Retention policy application" >> "$GITHUB_STEP_SUMMARY"
          echo "**Impact:** New backup uploaded successfully, old backups may not be cleaned up" >> "$GITHUB_STEP_SUMMARY"
          echo "**Action:** None required - new backup is safe, cleanup will retry next run" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        echo "" >> "$GITHUB_STEP_SUMMARY"
        echo "**Critical Guarantee:** Backup list was NOT modified during this failed run." >> "$GITHUB_STEP_SUMMARY"
        echo "All existing backups remain intact and accessible." >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"
        echo "**Next Steps:**" >> "$GITHUB_STEP_SUMMARY"
        echo "1. Review error logs above to identify root cause" >> "$GITHUB_STEP_SUMMARY"
        echo "2. Fix any configuration or permission issues" >> "$GITHUB_STEP_SUMMARY"
        echo "3. Retry backup workflow manually if needed" >> "$GITHUB_STEP_SUMMARY"
        echo "4. Next scheduled run will attempt backup again" >> "$GITHUB_STEP_SUMMARY"

    # Subtask 11.6: Add run summary with failure recovery status
    - name: Generate backup summary
      if: always()
      env:
        BACKUP_PAT: ${{ secrets.BACKUP_PAT }}
      run: |
        # Only generate summary if not already generated by failure handler
        if [ "${{ job.status }}" = "failure" ]; then
          echo "Summary already generated by failure handler"
          exit 0
        fi
        
        echo "" >> "$GITHUB_STEP_SUMMARY"
        echo "---" >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"
        echo "## ðŸ“Š Backup Summary" >> "$GITHUB_STEP_SUMMARY"
        echo "" >> "$GITHUB_STEP_SUMMARY"
        
        # Display backup status
        if [ "${{ steps.upload_backup.outputs.upload_success }}" = "true" ]; then
          echo "### âœ… Backup Successful" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          
          reason="${{ steps.backup_reason.outputs.reason }}"
          tier="${{ steps.backup_reason.outputs.tier }}"
          
          # Highlight failure recovery
          if [ "$reason" = "failure_recovery" ]; then
            echo "**âš ï¸  Failure Recovery Backup**" >> "$GITHUB_STEP_SUMMARY"
            echo "" >> "$GITHUB_STEP_SUMMARY"
            echo "This backup preserves partial progress from a failed collection run." >> "$GITHUB_STEP_SUMMARY"
            echo "The checkpoint contains ${{ steps.verification.outputs.node_count }} samples that were successfully collected before the failure." >> "$GITHUB_STEP_SUMMARY"
            echo "" >> "$GITHUB_STEP_SUMMARY"
          fi
          
          echo "**Backup Details:**" >> "$GITHUB_STEP_SUMMARY"
          echo "- Filename: \`${{ steps.create_backup.outputs.backup_filename }}\`" >> "$GITHUB_STEP_SUMMARY"
          echo "- Size: \`$(numfmt --to=iec-i --suffix=B ${{ steps.create_backup.outputs.backup_size }})\`" >> "$GITHUB_STEP_SUMMARY"
          echo "- Samples: \`${{ steps.verification.outputs.node_count }}\`" >> "$GITHUB_STEP_SUMMARY"
          echo "- Edges: \`${{ steps.verification.outputs.edge_count }}\`" >> "$GITHUB_STEP_SUMMARY"
          echo "- Tier: \`$tier\`" >> "$GITHUB_STEP_SUMMARY"
          echo "- Release: \`${{ steps.upload_backup.outputs.release_tag }}\`" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
        else
          echo "### âŒ Backup Failed" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          
          if [ "${{ steps.verification.outputs.verification_passed }}" != "true" ]; then
            echo "**Reason:** Checkpoint verification failed" >> "$GITHUB_STEP_SUMMARY"
          elif [ "${{ steps.create_backup.outputs.backup_created }}" != "true" ]; then
            echo "**Reason:** Backup creation failed" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "**Reason:** Backup upload failed" >> "$GITHUB_STEP_SUMMARY"
          fi
          echo "" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        # Display backup list status per tier
        if [ -n "$BACKUP_PAT" ]; then
          echo "**Backup Repository Status:**" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          
          REPO_OWNER="${{ github.repository_owner }}"
          BACKUP_REPO="${REPO_OWNER}/freesound-backup"
          
          # Check each tier
          for release_tag in v-recovery v-validated v-checkpoint v-permanent; do
            ASSETS_JSON=$(curl -s -H "Authorization: token $BACKUP_PAT" \
              "https://api.github.com/repos/${BACKUP_REPO}/releases/tags/${release_tag}")
            
            if echo "$ASSETS_JSON" | grep -q "Not Found"; then
              continue
            fi
            
            ASSET_COUNT=$(echo "$ASSETS_JSON" | jq '.assets | length')
            
            if [ "$ASSET_COUNT" -gt 0 ]; then
              # Get oldest asset age
              OLDEST_DATE=$(echo "$ASSETS_JSON" | jq -r '.assets | sort_by(.created_at) | .[0].created_at')
              OLDEST_AGE=$(( ($(date +%s) - $(date -d "$OLDEST_DATE" +%s 2>/dev/null || date -j -f "%Y-%m-%dT%H:%M:%SZ" "$OLDEST_DATE" +%s 2>/dev/null || echo "0")) / 86400 ))
              
              # Get retention policy
              case "$release_tag" in
                v-recovery) retention="7 days" ;;
                v-validated) retention="30 days" ;;
                v-checkpoint) retention="14 days" ;;
                v-permanent) retention="Unlimited" ;;
              esac
              
              echo "- **$release_tag**: $ASSET_COUNT backups (oldest: ${OLDEST_AGE}d, retention: $retention)" >> "$GITHUB_STEP_SUMMARY"
            fi
          done
          
          echo "" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        echo "**Retention Policies:**" >> "$GITHUB_STEP_SUMMARY"
        echo "- \`v-recovery\`: 7 days (failure recovery backups)" >> "$GITHUB_STEP_SUMMARY"
        echo "- \`v-validated\`: 30 days (validated checkpoints)" >> "$GITHUB_STEP_SUMMARY"
        echo "- \`v-checkpoint\`: 14 days (frequent backups from collection)" >> "$GITHUB_STEP_SUMMARY"
        echo "- \`v-permanent\`: Unlimited (milestone backups from collection)" >> "$GITHUB_STEP_SUMMARY"
