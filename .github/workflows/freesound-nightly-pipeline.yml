# Freesound Nightly Pipeline
#
# Automated pipeline that runs daily to continuously grow the Freesound sample library
# by consuming the daily API request allowance (2000 requests) and generating updated
# interactive visualizations.
#
# Architecture:
# - Persistent Storage: Private GitHub repository release assets (TOS-compliant)
# - Ephemeral Cache: Workflow cache populated from private repo at start, wiped at end
# - Split Checkpoint: Graph topology (.gpickle) + SQLite metadata (.db) + metadata JSON
#
# Backup Strategy (Triple Redundancy):
# 1. Primary Backup: Private repo with tiered retention (frequent: 14 days, permanent: unlimited)
# 2. Secondary Backup: Separate private repo with 7-day rolling history (disaster recovery)
# 3. Workflow Artifacts: 7-day retention for manual recovery (uploaded on every run)
#
# Features:
# - Scheduled execution at 2 AM UTC daily
# - Manual trigger with configurable parameters
# - Incremental data collection with checkpoint recovery
# - Automatic visualization generation
# - Backup on failure (preserves partial progress)
# - Triple-redundant backup system
# - Comprehensive logging and monitoring

name: Freesound Nightly Pipeline

on:
  schedule:
    # Run at 2 AM UTC Monday through Saturday (skip Sunday for validation)
    - cron: '0 2 * * 1-6'
  
  workflow_dispatch:
    # Allow manual triggering with custom parameters
    inputs:
      seed_sample_id:
        description: 'Seed sample ID (leave empty to use most downloaded sample)'
        required: false
        default: ''
        type: string
      max_requests:
        description: 'Maximum API requests (circuit breaker, default: 1950)'
        required: false
        default: '1950'
        type: string
      recursive_depth:
        description: 'Depth of recursive similar sound fetching'
        required: false
        default: '3'
        type: string

# Prevent workflow collisions
concurrency:
  group: freesound-pipeline
  cancel-in-progress: false

jobs:
  smoke-test:
    name: Pre-Flight Smoke Test
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: 'FollowWeb/requirements.txt'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        pip install -r FollowWeb/requirements.txt
        pip install -e FollowWeb/
    
    - name: Validate environment
      run: |
        echo "##  Pre-Flight Smoke Test" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Test 1: Package imports
        echo "###  Package Imports" >> $GITHUB_STEP_SUMMARY
        python -c "import FollowWeb_Visualizor" && echo "-  FollowWeb_Visualizor" >> $GITHUB_STEP_SUMMARY || { echo "-  FollowWeb_Visualizor" >> $GITHUB_STEP_SUMMARY; exit 1; }
        python -c "from FollowWeb_Visualizor.data.loaders import IncrementalFreesoundLoader" && echo "-  IncrementalFreesoundLoader" >> $GITHUB_STEP_SUMMARY || { echo "-  IncrementalFreesoundLoader" >> $GITHUB_STEP_SUMMARY; exit 1; }
        python -c "from FollowWeb_Visualizor.visualization.renderers import SigmaRenderer" && echo "-  SigmaRenderer" >> $GITHUB_STEP_SUMMARY || { echo "-  SigmaRenderer" >> $GITHUB_STEP_SUMMARY; exit 1; }
        python -c "import networkx" && echo "-  NetworkX" >> $GITHUB_STEP_SUMMARY || { echo "-  NetworkX" >> $GITHUB_STEP_SUMMARY; exit 1; }
        echo "" >> $GITHUB_STEP_SUMMARY
    
    - name: Validate secrets
      env:
        FREESOUND_API_KEY: ${{ secrets.FREESOUND_API_KEY }}
        BACKUP_PAT: ${{ secrets.BACKUP_PAT }}
        BACKUP_PAT_SECONDARY: ${{ secrets.BACKUP_PAT_SECONDARY }}
      run: |
        echo "###  Secret Validation" >> $GITHUB_STEP_SUMMARY
        
        # Check FREESOUND_API_KEY (required)
        if [ -z "$FREESOUND_API_KEY" ]; then
          echo "-  FREESOUND_API_KEY: Not configured" >> $GITHUB_STEP_SUMMARY
          echo "::error::FREESOUND_API_KEY not configured"
          exit 1
        else
          # Validate API key format (should be 32 hex characters)
          if [[ "$FREESOUND_API_KEY" =~ ^[a-f0-9]{32}$ ]]; then
            echo "-  FREESOUND_API_KEY: Valid format" >> $GITHUB_STEP_SUMMARY
          else
            echo "-  FREESOUND_API_KEY: Configured but format may be invalid" >> $GITHUB_STEP_SUMMARY
          fi
        fi
        
        # Check BACKUP_PAT (optional)
        if [ -z "$BACKUP_PAT" ]; then
          echo "-  BACKUP_PAT: Not configured (primary backups disabled)" >> $GITHUB_STEP_SUMMARY
        else
          echo "-  BACKUP_PAT: Configured (primary backup repository)" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Check BACKUP_PAT_SECONDARY (optional)
        if [ -z "$BACKUP_PAT_SECONDARY" ]; then
          echo "-  BACKUP_PAT_SECONDARY: Not configured (secondary backups disabled)" >> $GITHUB_STEP_SUMMARY
        else
          echo "-  BACKUP_PAT_SECONDARY: Configured (secondary backup repository)" >> $GITHUB_STEP_SUMMARY
        fi
        echo "" >> $GITHUB_STEP_SUMMARY
    
    - name: Test loader initialization (no API calls)
      env:
        FREESOUND_API_KEY: ${{ secrets.FREESOUND_API_KEY }}
      run: |
        echo "###  Component Tests" >> $GITHUB_STEP_SUMMARY
        
        # Test loader initialization without making API calls
        python -c "
        import os
        import tempfile
        from FollowWeb_Visualizor.data.loaders import IncrementalFreesoundLoader
        
        # Create temporary checkpoint directory
        with tempfile.TemporaryDirectory() as tmpdir:
            # Initialize loader (no API calls)
            # Loader reads FREESOUND_API_KEY from environment variable automatically
            loader = IncrementalFreesoundLoader(
                config={
                    'checkpoint': {
                        'checkpoint_dir': tmpdir,
                        'checkpoint_interval': 1
                    }
                }
            )
            
            # Verify loader attributes
            assert hasattr(loader, 'rate_limiter'), 'Rate limiter not initialized'
            assert hasattr(loader, 'graph'), 'Graph not initialized'
            assert hasattr(loader, 'processed_ids'), 'Processed IDs not initialized'
            
            # Verify initial state
            assert isinstance(loader.processed_ids, set), 'processed_ids should be a set'
            assert len(loader.processed_ids) == 0, 'processed_ids should start empty'
            assert loader.graph.number_of_nodes() == 0, 'Graph should start empty'
            
            print(' Loader initialization successful')
        " && echo "-  IncrementalFreesoundLoader initialization" >> $GITHUB_STEP_SUMMARY || { echo "-  IncrementalFreesoundLoader initialization" >> $GITHUB_STEP_SUMMARY; exit 1; }
        
        # Test renderer can be imported (initialization tested in actual pipeline)
        python -c "
        from FollowWeb_Visualizor.visualization.renderers import SigmaRenderer
        print(' SigmaRenderer import successful')
        " && echo "-  SigmaRenderer import" >> $GITHUB_STEP_SUMMARY || { echo "-  SigmaRenderer import" >> $GITHUB_STEP_SUMMARY; exit 1; }
        
        echo "" >> $GITHUB_STEP_SUMMARY
    
    - name: Test checkpoint operations (no API calls)
      run: |
        echo "###  Checkpoint Tests" >> $GITHUB_STEP_SUMMARY
        
        # Test checkpoint module can be imported (actual operations tested in pipeline)
        python -c "
        from FollowWeb_Visualizor.data.checkpoint import GraphCheckpoint
        from pathlib import Path
        
        # Verify checkpoint class can be instantiated
        checkpoint = GraphCheckpoint(Path('test_checkpoint.gpickle'))
        assert hasattr(checkpoint, 'checkpoint_path'), 'Checkpoint path not set'
        assert hasattr(checkpoint, 'save'), 'Save method not available'
        assert hasattr(checkpoint, 'load'), 'Load method not available'
        
        print(' Checkpoint module validated')
        " && echo "-  Checkpoint module validation" >> $GITHUB_STEP_SUMMARY || { echo "-  Checkpoint module validation" >> $GITHUB_STEP_SUMMARY; exit 1; }
        
        echo "" >> $GITHUB_STEP_SUMMARY
    
    - name: Test validation functions
      run: |
        echo "###  Validation Tests" >> $GITHUB_STEP_SUMMARY
        
        # Test validation utilities
        python -c "
        from FollowWeb_Visualizor.utils.validation import (
            validate_positive_integer,
            validate_non_negative_integer,
            validate_file_path
        )
        
        # Test positive integer validation
        try:
            validate_positive_integer(5, 'test')
            print(' Positive integer validation works')
        except:
            raise AssertionError('Positive integer validation failed')
        
        # Test that zero is rejected for positive integers
        try:
            validate_positive_integer(0, 'test')
            raise AssertionError('Should have rejected zero')
        except ValueError:
            print(' Zero correctly rejected for positive integers')
        
        # Test non-negative integer validation
        try:
            validate_non_negative_integer(0, 'test')
            print(' Non-negative integer validation works')
        except:
            raise AssertionError('Non-negative integer validation failed')
        
        print(' All validation tests passed')
        " && echo "-  Validation utilities" >> $GITHUB_STEP_SUMMARY || { echo "-  Validation utilities" >> $GITHUB_STEP_SUMMARY; exit 1; }
        
        echo "" >> $GITHUB_STEP_SUMMARY
    
    - name: Smoke test summary
      if: success()
      run: |
        echo "---" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "##  All Pre-Flight Checks Passed" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "The environment is ready for the Freesound Nightly Pipeline." >> $GITHUB_STEP_SUMMARY
        echo "Proceeding to data collection phase..." >> $GITHUB_STEP_SUMMARY

  freesound-pipeline:
    name: Freesound Data Collection & Visualization
    runs-on: ubuntu-latest
    timeout-minutes: 120  # 2-hour timeout
    needs: smoke-test  # Only run if smoke test passes
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for proper Git operations
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Configure Git
      run: |
        git config user.name "GitHub Actions Bot"
        git config user.email "actions@github.com"
        git config --global init.defaultBranch main
        git config --global advice.detachedHead false
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: 'FollowWeb/requirements.txt'
    
    - name: Display Python environment info
      run: |
        python --version
        python -c "import sys; print(f'Python executable: {sys.executable}')"
        python -c "import platform; print(f'Platform: {platform.platform()}')"
        pip --version
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        pip install -r FollowWeb/requirements.txt
        pip install -e FollowWeb/
    
    - name: Validate secrets
      env:
        FREESOUND_API_KEY: ${{ secrets.FREESOUND_API_KEY }}
        BACKUP_PAT: ${{ secrets.BACKUP_PAT }}
        BACKUP_PAT_SECONDARY: ${{ secrets.BACKUP_PAT_SECONDARY }}
      run: |
        echo "** Secret Validation**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check FREESOUND_API_KEY (required)
        if [ -z "$FREESOUND_API_KEY" ]; then
          echo "::error::FREESOUND_API_KEY not configured"
          echo "-  FREESOUND_API_KEY: Not configured" >> $GITHUB_STEP_SUMMARY
          exit 1
        else
          echo "-  FREESOUND_API_KEY: Configured" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Check BACKUP_PAT (optional but recommended)
        if [ -z "$BACKUP_PAT" ]; then
          echo "::warning::BACKUP_PAT not configured - primary checkpoint backups will be skipped"
          echo "-  BACKUP_PAT: Not configured (primary backups disabled)" >> $GITHUB_STEP_SUMMARY
        else
          echo "-  BACKUP_PAT: Configured (primary backup repository)" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Check BACKUP_PAT_SECONDARY (optional but recommended)
        if [ -z "$BACKUP_PAT_SECONDARY" ]; then
          echo "::warning::BACKUP_PAT_SECONDARY not configured - secondary checkpoint backups will be skipped"
          echo "-  BACKUP_PAT_SECONDARY: Not configured (secondary backups disabled)" >> $GITHUB_STEP_SUMMARY
        else
          echo "-  BACKUP_PAT_SECONDARY: Configured (secondary backup repository)" >> $GITHUB_STEP_SUMMARY
        fi
        echo "" >> $GITHUB_STEP_SUMMARY
    
    - name: Verify installation
      run: |
        python -c "import FollowWeb_Visualizor"
        echo " FollowWeb package imported successfully"
        python -c "from FollowWeb_Visualizor.data.loaders import IncrementalFreesoundLoader"
        echo " IncrementalFreesoundLoader available"
        python -c "from FollowWeb_Visualizor.visualization.renderers import SigmaRenderer"
        echo " SigmaRenderer available"
    
    - name: Set pipeline parameters
      id: params
      run: |
        # Use workflow_dispatch inputs if available, otherwise use defaults
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          echo "seed_sample_id=${{ github.event.inputs.seed_sample_id }}" >> $GITHUB_OUTPUT
          echo "max_requests=${{ github.event.inputs.max_requests }}" >> $GITHUB_OUTPUT
          echo "depth=${{ github.event.inputs.recursive_depth }}" >> $GITHUB_OUTPUT
        else
          echo "seed_sample_id=" >> $GITHUB_OUTPUT
          echo "max_requests=1950" >> $GITHUB_OUTPUT
          echo "depth=3" >> $GITHUB_OUTPUT
        fi
        
        # Generate execution ID
        echo "execution_id=$(date +'%Y%m%d_%H%M%S')" >> $GITHUB_OUTPUT
    
    - name: Download checkpoint from private repository
      id: download_checkpoint
      env:
        BACKUP_PAT: ${{ secrets.BACKUP_PAT }}
      run: |
        echo "** Phase 1: Download Checkpoint from Private Repository**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check if BACKUP_PAT is configured
        if [ -z "$BACKUP_PAT" ]; then
          echo " BACKUP_PAT not configured, starting with empty checkpoint"
          echo "- Status: No backup available" >> $GITHUB_STEP_SUMMARY
          echo "checkpoint_restored=false" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        # Get repository owner and name from GITHUB_REPOSITORY
        REPO_OWNER="${{ github.repository_owner }}"
        BACKUP_REPO="${REPO_OWNER}/freesound-backup"
        
        # List all assets from v-checkpoint release
        echo "Fetching assets from ${BACKUP_REPO} release v-checkpoint..."
        ASSETS_JSON=$(curl -s -H "Authorization: token $BACKUP_PAT" \
          "https://api.github.com/repos/${BACKUP_REPO}/releases/tags/v-checkpoint")
        
        # Check if release exists
        if echo "$ASSETS_JSON" | grep -q "Not Found"; then
          echo " Release v-checkpoint not found in ${BACKUP_REPO}"
          echo "- Status: No backup available" >> $GITHUB_STEP_SUMMARY
          echo "checkpoint_restored=false" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        # Find most recent checkpoint backup
        LATEST_ASSET=$(echo "$ASSETS_JSON" | jq -r '.assets | sort_by(.created_at) | reverse | .[0]')
        
        if [ "$LATEST_ASSET" = "null" ] || [ -z "$LATEST_ASSET" ]; then
          echo " No checkpoint backups found in ${BACKUP_REPO}"
          echo "- Status: No backup available" >> $GITHUB_STEP_SUMMARY
          echo "checkpoint_restored=false" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        # Extract asset details
        ASSET_NAME=$(echo "$LATEST_ASSET" | jq -r '.name')
        ASSET_URL=$(echo "$LATEST_ASSET" | jq -r '.url')
        ASSET_SIZE=$(echo "$LATEST_ASSET" | jq -r '.size')
        ASSET_CREATED=$(echo "$LATEST_ASSET" | jq -r '.created_at')
        
        echo " Found latest backup: $ASSET_NAME"
        echo "- Size: $(numfmt --to=iec-i --suffix=B $ASSET_SIZE)"
        echo "- Created: $ASSET_CREATED"
        
        # Download asset
        echo "Downloading checkpoint backup..."
        curl -L -H "Authorization: token $BACKUP_PAT" \
          -H "Accept: application/octet-stream" \
          "$ASSET_URL" -o checkpoint_backup.tar.gz
        
        # Extract to data/freesound_library/
        echo "Extracting checkpoint to data/freesound_library/..."
        mkdir -p data/freesound_library
        tar -xzf checkpoint_backup.tar.gz -C data/
        
        # Verify extraction
        if [ -f "data/freesound_library/graph_topology.gpickle" ]; then
          echo " Checkpoint restored successfully"
          echo "- Backup: \`$ASSET_NAME\`" >> $GITHUB_STEP_SUMMARY
          echo "- Size: \`$(numfmt --to=iec-i --suffix=B $ASSET_SIZE)\`" >> $GITHUB_STEP_SUMMARY
          echo "- Created: \`$ASSET_CREATED\`" >> $GITHUB_STEP_SUMMARY
          echo "checkpoint_restored=true" >> $GITHUB_OUTPUT
        else
          echo " Checkpoint extraction failed"
          echo "- Status: Extraction failed" >> $GITHUB_STEP_SUMMARY
          echo "checkpoint_restored=false" >> $GITHUB_OUTPUT
        fi
        
        # Cleanup
        rm -f checkpoint_backup.tar.gz
    
    - name: Check for workflow conflicts
      id: orchestration
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # Skip orchestration check for now - workflow_orchestrator not in repo
        echo "can_proceed=true" >> $GITHUB_OUTPUT
        echo "skip_reason=No conflicts" >> $GITHUB_OUTPUT
    
    - name: Display pipeline configuration
      if: steps.orchestration.outputs.can_proceed == 'true'
      run: |
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "** Phase 2: Pipeline Configuration**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        if [ -n "${{ steps.params.outputs.seed_sample_id }}" ]; then
          echo "- Seed Sample ID: \`${{ steps.params.outputs.seed_sample_id }}\`" >> $GITHUB_STEP_SUMMARY
        else
          echo "- Seed Sample: \`Most downloaded sample (auto-detected)\`" >> $GITHUB_STEP_SUMMARY
        fi
        echo "- Max Requests: \`${{ steps.params.outputs.max_requests }}\` (circuit breaker)" >> $GITHUB_STEP_SUMMARY
        echo "- Recursive Depth: \`${{ steps.params.outputs.depth }}\`" >> $GITHUB_STEP_SUMMARY
        echo "- Execution ID: \`${{ steps.params.outputs.execution_id }}\`" >> $GITHUB_STEP_SUMMARY
        echo "- Trigger: \`${{ github.event_name }}\`" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
    
    - name: Run data collection and visualization
      if: steps.orchestration.outputs.can_proceed == 'true'
      id: pipeline
      env:
        FREESOUND_API_KEY: ${{ secrets.FREESOUND_API_KEY }}
      run: |
        echo "** Phase 3: Data Collection**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Build command with optional seed sample ID
        cmd="python generate_freesound_visualization.py"
        if [ -n "${{ steps.params.outputs.seed_sample_id }}" ]; then
          cmd="$cmd --seed-sample-id ${{ steps.params.outputs.seed_sample_id }}"
        fi
        cmd="$cmd --max-requests ${{ steps.params.outputs.max_requests }}"
        cmd="$cmd --depth ${{ steps.params.outputs.depth }}"
        
        # Run the pipeline script
        eval "$cmd" 2>&1 | tee pipeline_${{ steps.params.outputs.execution_id }}.log
        
        # Capture exit code
        pipeline_exit_code=${PIPESTATUS[0]}
        
        if [ $pipeline_exit_code -eq 0 ]; then
          echo " Data collection and visualization completed successfully"
          echo "pipeline_status=success" >> $GITHUB_OUTPUT
        else
          echo " Pipeline failed with exit code: $pipeline_exit_code"
          echo "pipeline_status=failed" >> $GITHUB_OUTPUT
          exit $pipeline_exit_code
        fi
    
    - name: Append execution metrics
      if: steps.pipeline.outputs.pipeline_status == 'success'
      run: |
        # Extract metrics from log
        log_file="pipeline_${{ steps.params.outputs.execution_id }}.log"
        
        # Create metrics entry
        timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
        nodes_added=$(grep -oP "(?<=Nodes added: )\d+" "$log_file" | tail -1 || echo "0")
        edges_added=$(grep -oP "(?<=Edges added: )\d+" "$log_file" | tail -1 || echo "0")
        api_requests=$(grep -oP "(?<=API requests: )\d+" "$log_file" | tail -1 || echo "0")
        duration=$(grep -oP "(?<=Duration: )\d+" "$log_file" | tail -1 || echo "0")
        
        # Append to metrics history
        mkdir -p data
        echo "{\"timestamp\":\"$timestamp\",\"nodes_added\":$nodes_added,\"edges_added\":$edges_added,\"api_requests\":$api_requests,\"duration\":$duration}" >> data/metrics_history.jsonl
        
        echo " Metrics appended to history"
    
    - name: Check for milestone
      if: steps.pipeline.outputs.pipeline_status == 'success'
      id: milestone
      run: |
        python detect_milestone.py \
          --checkpoint-dir data/freesound_library \
          --output milestone_status.json
        
        # Parse output
        is_milestone=$(jq -r '.is_milestone' milestone_status.json)
        milestone_number=$(jq -r '.milestone_number' milestone_status.json)
        current_nodes=$(jq -r '.current_nodes' milestone_status.json)
        
        echo "is_milestone=$is_milestone" >> $GITHUB_OUTPUT
        echo "milestone_number=$milestone_number" >> $GITHUB_OUTPUT
        echo "current_nodes=$current_nodes" >> $GITHUB_OUTPUT
        
        if [ "$is_milestone" = "true" ]; then
          echo " Milestone $milestone_number detected at $current_nodes nodes!"
        fi
    
    - name: Run milestone actions in parallel
      if: steps.milestone.outputs.is_milestone == 'true'
      id: milestone_actions
      run: |
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "** Milestone ${{ steps.milestone.outputs.milestone_number }} Reached!**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "Current nodes: \`${{ steps.milestone.outputs.current_nodes }}\`" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "** Running Milestone Actions in Parallel**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Start background jobs
        echo "Starting parallel jobs..."
        
        # Job 1: Validation (background)
        (
          echo "Starting validation job..."
          python validate_pipeline_data.py \
            --checkpoint-dir data/freesound_library \
            --metrics-history data/metrics_history.jsonl \
            --output validation_report.json 2>&1 | tee validation.log
          echo $? > validation_exit_code.txt
        ) &
        VALIDATION_PID=$!
        
        # Job 2: Edge generation (background)
        (
          echo "Starting edge generation job..."
          python generate_user_pack_edges.py \
            --checkpoint-dir data/freesound_library \
            --output edge_stats.json 2>&1 | tee edge_generation.log
          echo $? > edges_exit_code.txt
        ) &
        EDGES_PID=$!
        
        # Job 3: Website deployment (background)
        (
          echo "Starting website generation job..."
          python generate_landing_page.py \
            --output-dir website \
            --metrics-history data/metrics_history.jsonl \
            --milestone-history data/milestone_history.jsonl \
            --visualizations Output/*.html 2>&1 | tee website.log
          echo $? > website_exit_code.txt
        ) &
        WEBSITE_PID=$!
        
        # Wait for all jobs to complete
        echo "Waiting for parallel jobs to complete..."
        echo "- Validation PID: $VALIDATION_PID"
        echo "- Edge Generation PID: $EDGES_PID"
        echo "- Website PID: $WEBSITE_PID"
        
        wait $VALIDATION_PID
        wait $EDGES_PID
        wait $WEBSITE_PID
        
        # Check exit codes
        validation_code=$(cat validation_exit_code.txt)
        edges_code=$(cat edges_exit_code.txt)
        website_code=$(cat website_exit_code.txt)
        
        echo "Exit codes: validation=$validation_code, edges=$edges_code, website=$website_code"
        
        # Log results to summary
        echo "### Parallel Job Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ $validation_code -eq 0 ]; then
          echo "-  **Validation**: Passed" >> $GITHUB_STEP_SUMMARY
        else
          echo "-  **Validation**: Failed (exit code: $validation_code)" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ $edges_code -eq 0 ]; then
          if [ -f edge_stats.json ]; then
            user_edges=$(jq -r '.user_edges_added // 0' edge_stats.json)
            pack_edges=$(jq -r '.pack_edges_added // 0' edge_stats.json)
            echo "-  **Edge Generation**: $user_edges user edges, $pack_edges pack edges" >> $GITHUB_STEP_SUMMARY
          else
            echo "-  **Edge Generation**: Completed" >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "-  **Edge Generation**: Failed (exit code: $edges_code)" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ $website_code -eq 0 ]; then
          echo "-  **Website**: Generated" >> $GITHUB_STEP_SUMMARY
        else
          echo "-  **Website**: Failed (exit code: $website_code)" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Store exit codes for later steps
        echo "validation_code=$validation_code" >> $GITHUB_OUTPUT
        echo "edges_code=$edges_code" >> $GITHUB_OUTPUT
        echo "website_code=$website_code" >> $GITHUB_OUTPUT
        
        # Fail if validation failed (critical)
        if [ $validation_code -ne 0 ]; then
          echo "::error::Validation failed - this is a critical error"
          exit 1
        fi
        
        # Warn if edge generation or website failed (non-critical)
        if [ $edges_code -ne 0 ] || [ $website_code -ne 0 ]; then
          echo "::warning::Some milestone actions failed but pipeline continues"
        fi
    
    - name: Upload checkpoint to private repository
      if: steps.orchestration.outputs.can_proceed == 'true' && always()
      id: upload_checkpoint
      env:
        BACKUP_PAT: ${{ secrets.BACKUP_PAT }}
      run: |
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "** Phase 4: Upload Checkpoint to Private Repository**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check if checkpoint directory exists
        if [ ! -d "data/freesound_library" ]; then
          echo " Checkpoint directory not found, skipping backup"
          echo "- Status: Backup skipped (no checkpoint)" >> $GITHUB_STEP_SUMMARY
          exit 0
        fi
        
        # Check if BACKUP_PAT is configured
        if [ -z "$BACKUP_PAT" ]; then
          echo " BACKUP_PAT not configured, skipping backup upload"
          echo "- Status: Backup skipped (PAT not configured)" >> $GITHUB_STEP_SUMMARY
          exit 0
        fi
        
        # Determine backup tier based on node count
        if [ -f "data/freesound_library/checkpoint_metadata.json" ]; then
          node_count=$(jq -r '.total_nodes // 0' data/freesound_library/checkpoint_metadata.json)
        else
          echo "::warning::Checkpoint metadata not found - data may be incomplete"
          echo "- Status: ⚠️ Metadata missing (data integrity issue)" >> $GITHUB_STEP_SUMMARY
          echo "- Action: Creating backup anyway, but remediation recommended" >> $GITHUB_STEP_SUMMARY
          # Try to get node count from graph file
          if [ -f "data/freesound_library/graph_topology.gpickle" ]; then
            node_count=$(python3 -c "import pickle; g = pickle.load(open('data/freesound_library/graph_topology.gpickle', 'rb')); print(g.number_of_nodes())" 2>/dev/null || echo "0")
            echo "- Estimated nodes from graph: $node_count" >> $GITHUB_STEP_SUMMARY
          else
            node_count=0
            echo "- No graph file found either" >> $GITHUB_STEP_SUMMARY
          fi
        fi
        
        # Check if this is a failure recovery backup
        pipeline_status="${{ steps.pipeline.outputs.pipeline_status }}"
        if [ "$pipeline_status" != "success" ]; then
          echo " Pipeline failed - creating recovery backup"
          echo "- Status: Recovery backup (pipeline failed)" >> $GITHUB_STEP_SUMMARY
          # Force backup creation regardless of interval
          tier="recovery"
          release_tag="v-checkpoint"
        else
          echo "Current node count: $node_count"
          
          # Determine tier and release tag using Python
          tier_info=$(python3 -c "import sys; node_count = $node_count; backup_interval = 25; tier = 'milestone' if node_count % (backup_interval * 20) == 0 else ('moderate' if node_count % (backup_interval * 4) == 0 else ('frequent' if node_count % backup_interval == 0 else 'none')); release_tag = 'v-permanent' if tier in ['milestone', 'moderate'] else ('v-checkpoint' if tier == 'frequent' else 'none'); print(f'{tier}|{release_tag}')")
          
          tier=$(echo "$tier_info" | cut -d'|' -f1)
          release_tag=$(echo "$tier_info" | cut -d'|' -f2)
          
          # Check if backup should be created
          if [ "$tier" = "none" ]; then
            echo " Node count ($node_count) not at backup interval, skipping backup"
            echo "- Status: Backup skipped (not at interval)" >> $GITHUB_STEP_SUMMARY
            exit 0
          fi
        fi
        
        echo "Backup tier: $tier"
        echo "Release tag: $release_tag"
        
        # Create tar.gz archive with tier information in filename
        backup_filename="checkpoint_backup_${node_count}nodes_${tier}_${{ github.run_id }}.tar.gz"
        echo "Creating backup archive: $backup_filename"
        tar -czf "$backup_filename" -C data freesound_library/
        
        # Get file size
        backup_size=$(stat -f%z "$backup_filename" 2>/dev/null || stat -c%s "$backup_filename")
        echo "Backup size: $(numfmt --to=iec-i --suffix=B $backup_size)"
        
        # Get repository details
        REPO_OWNER="${{ github.repository_owner }}"
        BACKUP_REPO="${REPO_OWNER}/freesound-backup"
        
        # Get release ID for the appropriate tag
        RELEASE_JSON=$(curl -s -H "Authorization: token $BACKUP_PAT" \
          "https://api.github.com/repos/${BACKUP_REPO}/releases/tags/${release_tag}")
        
        RELEASE_ID=$(echo "$RELEASE_JSON" | jq -r '.id')
        
        if [ "$RELEASE_ID" = "null" ] || [ -z "$RELEASE_ID" ]; then
          echo " Release ${release_tag} not found in ${BACKUP_REPO}"
          echo "- Status: Upload failed (release not found)" >> $GITHUB_STEP_SUMMARY
          echo "- Tier: \`$tier\`" >> $GITHUB_STEP_SUMMARY
          echo "- Release Tag: \`$release_tag\`" >> $GITHUB_STEP_SUMMARY
          exit 1
        fi
        
        # Upload asset
        echo "Uploading backup to ${BACKUP_REPO} (release: ${release_tag})..."
        UPLOAD_URL="https://uploads.github.com/repos/${BACKUP_REPO}/releases/${RELEASE_ID}/assets?name=${backup_filename}"
        
        UPLOAD_RESPONSE=$(curl -s -X POST \
          -H "Authorization: token $BACKUP_PAT" \
          -H "Content-Type: application/gzip" \
          --data-binary "@${backup_filename}" \
          "$UPLOAD_URL")
        
        ASSET_ID=$(echo "$UPLOAD_RESPONSE" | jq -r '.id')
        
        if [ "$ASSET_ID" = "null" ] || [ -z "$ASSET_ID" ]; then
          echo " Failed to upload backup"
          echo "- Status: Upload failed" >> $GITHUB_STEP_SUMMARY
          exit 1
        fi
        
        echo " Backup uploaded successfully"
        echo "- Backup: \`$backup_filename\`" >> $GITHUB_STEP_SUMMARY
        echo "- Tier: \`$tier\`" >> $GITHUB_STEP_SUMMARY
        echo "- Release Tag: \`$release_tag\`" >> $GITHUB_STEP_SUMMARY
        echo "- Size: \`$(numfmt --to=iec-i --suffix=B $backup_size)\`" >> $GITHUB_STEP_SUMMARY
        echo "- Node Count: \`$node_count\`" >> $GITHUB_STEP_SUMMARY
        echo "- Run ID: \`${{ github.run_id }}\`" >> $GITHUB_STEP_SUMMARY
        
        # Store tier info for retention cleanup
        echo "backup_tier=$tier" >> $GITHUB_OUTPUT
        echo "release_tag=$release_tag" >> $GITHUB_OUTPUT
        echo "backup_uploaded=true" >> $GITHUB_OUTPUT
        
        # Cleanup local backup file
        rm -f "$backup_filename"
    
    - name: Verify backup integrity
      if: steps.upload_checkpoint.outputs.backup_uploaded == 'true'
      env:
        BACKUP_PAT: ${{ secrets.BACKUP_PAT }}
      run: |
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "** Phase 4a: Verify Backup Integrity**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        REPO_OWNER="${{ github.repository_owner }}"
        BACKUP_REPO="${REPO_OWNER}/freesound-backup"
        release_tag="${{ steps.upload_checkpoint.outputs.release_tag }}"
        
        # Get the most recent asset from the release
        RELEASE_JSON=$(curl -s -H "Authorization: token $BACKUP_PAT" \
          "https://api.github.com/repos/${BACKUP_REPO}/releases/tags/${release_tag}")
        
        LATEST_ASSET=$(echo "$RELEASE_JSON" | jq -r '.assets | sort_by(.created_at) | reverse | .[0]')
        
        if [ "$LATEST_ASSET" = "null" ] || [ -z "$LATEST_ASSET" ]; then
          echo " Could not verify backup - asset not found"
          echo "- Status: Verification skipped" >> $GITHUB_STEP_SUMMARY
          exit 0
        fi
        
        ASSET_NAME=$(echo "$LATEST_ASSET" | jq -r '.name')
        ASSET_SIZE=$(echo "$LATEST_ASSET" | jq -r '.size')
        ASSET_STATE=$(echo "$LATEST_ASSET" | jq -r '.state')
        
        echo "Verifying backup: $ASSET_NAME"
        echo "- Size: $(numfmt --to=iec-i --suffix=B $ASSET_SIZE)"
        echo "- State: $ASSET_STATE"
        
        # Verify asset state is 'uploaded'
        if [ "$ASSET_STATE" != "uploaded" ]; then
          echo " Backup verification failed - asset state: $ASSET_STATE"
          echo "- Status:  Verification failed" >> $GITHUB_STEP_SUMMARY
          echo "- Asset State: \`$ASSET_STATE\`" >> $GITHUB_STEP_SUMMARY
          exit 1
        fi
        
        # Verify asset size is reasonable (> 1KB)
        if [ "$ASSET_SIZE" -lt 1024 ]; then
          echo " Backup verification failed - asset too small: $ASSET_SIZE bytes"
          echo "- Status:  Verification failed" >> $GITHUB_STEP_SUMMARY
          echo "- Asset Size: \`$ASSET_SIZE bytes\` (too small)" >> $GITHUB_STEP_SUMMARY
          exit 1
        fi
        
        echo " Backup verification passed"
        echo "- Status:  Verified" >> $GITHUB_STEP_SUMMARY
        echo "- Asset: \`$ASSET_NAME\`" >> $GITHUB_STEP_SUMMARY
        echo "- Size: \`$(numfmt --to=iec-i --suffix=B $ASSET_SIZE)\`" >> $GITHUB_STEP_SUMMARY
        echo "- State: \`$ASSET_STATE\`" >> $GITHUB_STEP_SUMMARY
    
    - name: Upload checkpoint to secondary backup repository
      if: steps.orchestration.outputs.can_proceed == 'true' && (steps.pipeline.outputs.pipeline_status == 'success' || failure())
      id: upload_secondary_backup
      env:
        BACKUP_PAT_SECONDARY: ${{ secrets.BACKUP_PAT_SECONDARY }}
      run: |
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "** Phase 4b: Upload to Secondary Backup Repository (7-Day History)**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check if checkpoint directory exists
        if [ ! -d "data/freesound_library" ]; then
          echo " Checkpoint directory not found, skipping secondary backup"
          echo "- Status: Backup skipped (no checkpoint)" >> $GITHUB_STEP_SUMMARY
          exit 0
        fi
        
        # Check if BACKUP_PAT_SECONDARY is configured
        if [ -z "$BACKUP_PAT_SECONDARY" ]; then
          echo " BACKUP_PAT_SECONDARY not configured, skipping secondary backup"
          echo "- Status: Backup skipped (PAT not configured)" >> $GITHUB_STEP_SUMMARY
          exit 0
        fi
        
        # Get node count for filename
        if [ -f "data/freesound_library/checkpoint_metadata.json" ]; then
          node_count=$(jq -r '.total_nodes // 0' data/freesound_library/checkpoint_metadata.json)
        else
          node_count="unknown"
        fi
        
        # Create backup with timestamp for 7-day history tracking
        timestamp=$(date -u +"%Y%m%d_%H%M%S")
        backup_filename="checkpoint_backup_${node_count}nodes_${timestamp}_${{ github.run_id }}.tar.gz"
        echo "Creating secondary backup archive: $backup_filename"
        tar -czf "$backup_filename" -C data freesound_library/
        
        # Get file size
        backup_size=$(stat -f%z "$backup_filename" 2>/dev/null || stat -c%s "$backup_filename")
        echo "Backup size: $(numfmt --to=iec-i --suffix=B $backup_size)"
        
        # Get repository details
        REPO_OWNER="${{ github.repository_owner }}"
        SECONDARY_BACKUP_REPO="${REPO_OWNER}/freesound-backup-secondary"
        
        # Get release ID for v-daily tag (7-day rolling history)
        RELEASE_JSON=$(curl -s -H "Authorization: token $BACKUP_PAT_SECONDARY" \
          "https://api.github.com/repos/${SECONDARY_BACKUP_REPO}/releases/tags/v-daily")
        
        RELEASE_ID=$(echo "$RELEASE_JSON" | jq -r '.id')
        
        if [ "$RELEASE_ID" = "null" ] || [ -z "$RELEASE_ID" ]; then
          echo " Release v-daily not found in ${SECONDARY_BACKUP_REPO}"
          echo "- Status: Upload failed (release not found)" >> $GITHUB_STEP_SUMMARY
          echo "- Note: Create release 'v-daily' in ${SECONDARY_BACKUP_REPO}" >> $GITHUB_STEP_SUMMARY
          rm -f "$backup_filename"
          exit 0  # Don't fail the workflow
        fi
        
        # Upload asset
        echo "Uploading backup to ${SECONDARY_BACKUP_REPO} (release: v-daily)..."
        UPLOAD_URL="https://uploads.github.com/repos/${SECONDARY_BACKUP_REPO}/releases/${RELEASE_ID}/assets?name=${backup_filename}"
        
        UPLOAD_RESPONSE=$(curl -s -X POST \
          -H "Authorization: token $BACKUP_PAT_SECONDARY" \
          -H "Content-Type: application/gzip" \
          --data-binary "@${backup_filename}" \
          "$UPLOAD_URL")
        
        ASSET_ID=$(echo "$UPLOAD_RESPONSE" | jq -r '.id')
        
        if [ "$ASSET_ID" = "null" ] || [ -z "$ASSET_ID" ]; then
          echo " Failed to upload secondary backup"
          echo "- Status: Upload failed" >> $GITHUB_STEP_SUMMARY
          rm -f "$backup_filename"
          exit 0  # Don't fail the workflow
        fi
        
        echo " Secondary backup uploaded successfully"
        echo "- Backup: \`$backup_filename\`" >> $GITHUB_STEP_SUMMARY
        echo "- Repository: \`${SECONDARY_BACKUP_REPO}\`" >> $GITHUB_STEP_SUMMARY
        echo "- Release Tag: \`v-daily\`" >> $GITHUB_STEP_SUMMARY
        echo "- Size: \`$(numfmt --to=iec-i --suffix=B $backup_size)\`" >> $GITHUB_STEP_SUMMARY
        echo "- Node Count: \`$node_count\`" >> $GITHUB_STEP_SUMMARY
        echo "- Retention: \`7 days\`" >> $GITHUB_STEP_SUMMARY
        
        # Cleanup local backup file
        rm -f "$backup_filename"
    
    - name: Cleanup secondary backup repository (7-day retention)
      if: steps.upload_secondary_backup.outcome == 'success'
      env:
        BACKUP_PAT_SECONDARY: ${{ secrets.BACKUP_PAT_SECONDARY }}
      run: |
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "** Phase 4c: Secondary Backup Retention (7-Day Policy)**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        REPO_OWNER="${{ github.repository_owner }}"
        SECONDARY_BACKUP_REPO="${REPO_OWNER}/freesound-backup-secondary"
        
        # Get all assets from v-daily release
        ASSETS_JSON=$(curl -s -H "Authorization: token $BACKUP_PAT_SECONDARY" \
          "https://api.github.com/repos/${SECONDARY_BACKUP_REPO}/releases/tags/v-daily")
        
        TOTAL_ASSETS=$(echo "$ASSETS_JSON" | jq '.assets | length')
        echo "Total secondary backups: $TOTAL_ASSETS"
        
        # Apply 7-day retention policy
        CUTOFF_DATE=$(date -u -d '7 days ago' +%Y-%m-%dT%H:%M:%SZ 2>/dev/null || date -u -v-7d +%Y-%m-%dT%H:%M:%S 2>/dev/null || echo "")
        
        if [ -n "$CUTOFF_DATE" ]; then
          echo "Cutoff date for secondary backups: $CUTOFF_DATE"
          
          # Get assets older than 7 days
          ASSETS_TO_DELETE=$(echo "$ASSETS_JSON" | jq -r ".assets | map(select(.created_at < \"$CUTOFF_DATE\")) | .[].id")
          
          DELETED_COUNT=0
          for ASSET_ID in $ASSETS_TO_DELETE; do
            echo "Deleting old secondary backup asset ID: $ASSET_ID"
            curl -s -X DELETE \
              -H "Authorization: token $BACKUP_PAT_SECONDARY" \
              "https://api.github.com/repos/${SECONDARY_BACKUP_REPO}/releases/assets/${ASSET_ID}"
            
            if [ $? -eq 0 ]; then
              DELETED_COUNT=$((DELETED_COUNT + 1))
            else
              echo " Failed to delete asset $ASSET_ID"
            fi
          done
          
          RETAINED_COUNT=$((TOTAL_ASSETS - DELETED_COUNT))
          echo "- Retention: \`7 days\`" >> $GITHUB_STEP_SUMMARY
          echo "- Backups retained: \`$RETAINED_COUNT\`" >> $GITHUB_STEP_SUMMARY
          echo "- Backups deleted: \`$DELETED_COUNT\`" >> $GITHUB_STEP_SUMMARY
        else
          echo " Could not calculate cutoff date, skipping cleanup"
          echo "- Status: Cleanup skipped (date calculation failed)" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo " Secondary backup retention cleanup complete"
    
    - name: Upload checkpoint files as workflow artifacts
      if: always() && steps.orchestration.outputs.can_proceed == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: checkpoint-backup-${{ steps.params.outputs.execution_id }}
        path: |
          data/freesound_library/*.gpickle
          data/freesound_library/*.db
          data/freesound_library/*.json
        retention-days: 7
        if-no-files-found: ignore
    
    - name: Cleanup old backups (retention policy)
      if: steps.orchestration.outputs.can_proceed == 'true' && steps.pipeline.outputs.pipeline_status == 'success'
      env:
        BACKUP_PAT: ${{ secrets.BACKUP_PAT }}
      run: |
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "** Phase 5: Backup Retention Policy**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check if BACKUP_PAT is configured
        if [ -z "$BACKUP_PAT" ]; then
          echo " BACKUP_PAT not configured, skipping retention cleanup"
          exit 0
        fi
        
        REPO_OWNER="${{ github.repository_owner }}"
        BACKUP_REPO="${REPO_OWNER}/freesound-backup"
        
        # Process v-checkpoint release (frequent tier with 14-day retention)
        echo "### v-checkpoint Release (Frequent Tier)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        CHECKPOINT_ASSETS_JSON=$(curl -s -H "Authorization: token $BACKUP_PAT" \
          "https://api.github.com/repos/${BACKUP_REPO}/releases/tags/v-checkpoint")
        
        CHECKPOINT_TOTAL=$(echo "$CHECKPOINT_ASSETS_JSON" | jq '.assets | length')
        echo "Total v-checkpoint backups: $CHECKPOINT_TOTAL"
        
        # Apply 14-day retention policy for frequent backups
        CUTOFF_DATE=$(date -u -d '14 days ago' +%Y-%m-%dT%H:%M:%SZ 2>/dev/null || date -u -v-14d +%Y-%m-%dT%H:%M:%S 2>/dev/null || echo "")
        
        if [ -n "$CUTOFF_DATE" ]; then
          echo "Cutoff date for frequent backups: $CUTOFF_DATE"
          
          # Get assets older than 14 days
          CHECKPOINT_TO_DELETE=$(echo "$CHECKPOINT_ASSETS_JSON" | jq -r ".assets | map(select(.created_at < \"$CUTOFF_DATE\")) | .[].id")
          
          CHECKPOINT_DELETED=0
          for ASSET_ID in $CHECKPOINT_TO_DELETE; do
            echo "Deleting old v-checkpoint asset ID: $ASSET_ID"
            curl -s -X DELETE \
              -H "Authorization: token $BACKUP_PAT" \
              "https://api.github.com/repos/${BACKUP_REPO}/releases/assets/${ASSET_ID}"
            
            if [ $? -eq 0 ]; then
              CHECKPOINT_DELETED=$((CHECKPOINT_DELETED + 1))
            else
              echo " Failed to delete asset $ASSET_ID"
            fi
          done
          
          CHECKPOINT_RETAINED=$((CHECKPOINT_TOTAL - CHECKPOINT_DELETED))
          echo "- Retention: \`14 days\`" >> $GITHUB_STEP_SUMMARY
          echo "- Backups retained: \`$CHECKPOINT_RETAINED\`" >> $GITHUB_STEP_SUMMARY
          echo "- Backups deleted: \`$CHECKPOINT_DELETED\`" >> $GITHUB_STEP_SUMMARY
        else
          echo " Could not calculate cutoff date, skipping time-based cleanup"
          echo "- Status: Cleanup skipped (date calculation failed)" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Also enforce max count limit (keep last 10 backups)
        MAX_CHECKPOINT_BACKUPS=10
        if [ "$CHECKPOINT_TOTAL" -gt "$MAX_CHECKPOINT_BACKUPS" ]; then
          TO_DELETE=$((CHECKPOINT_TOTAL - MAX_CHECKPOINT_BACKUPS))
          echo "Enforcing max count limit: deleting $TO_DELETE oldest backups..."
          
          OLDEST_ASSETS=$(echo "$CHECKPOINT_ASSETS_JSON" | jq -r ".assets | sort_by(.created_at) | .[:$TO_DELETE] | .[].id")
          
          for ASSET_ID in $OLDEST_ASSETS; do
            echo "Deleting old v-checkpoint asset ID: $ASSET_ID"
            curl -s -X DELETE \
              -H "Authorization: token $BACKUP_PAT" \
              "https://api.github.com/repos/${BACKUP_REPO}/releases/assets/${ASSET_ID}"
          done
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Process v-permanent release (moderate and milestone tiers - no deletion)
        echo "### v-permanent Release (Moderate & Milestone Tiers)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        PERMANENT_ASSETS_JSON=$(curl -s -H "Authorization: token $BACKUP_PAT" \
          "https://api.github.com/repos/${BACKUP_REPO}/releases/tags/v-permanent")
        
        PERMANENT_TOTAL=$(echo "$PERMANENT_ASSETS_JSON" | jq '.assets | length')
        echo "Total v-permanent backups: $PERMANENT_TOTAL"
        
        # No deletion for permanent backups
        echo "- Retention: \`Permanent (no expiration)\`" >> $GITHUB_STEP_SUMMARY
        echo "- Backups retained: \`$PERMANENT_TOTAL\`" >> $GITHUB_STEP_SUMMARY
        echo "- Backups deleted: \`0\` (permanent tier never deleted)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        echo " Tier-specific retention cleanup complete"
    
    - name: Extract pipeline statistics
      if: steps.orchestration.outputs.can_proceed == 'true' && steps.pipeline.outputs.pipeline_status == 'success'
      id: stats
      run: |
        # Extract statistics from log file
        log_file="pipeline_${{ steps.params.outputs.execution_id }}.log"
        
        # Extract nodes and edges statistics
        nodes_added=$(grep -oP "(?<=Nodes added: )\d+" "$log_file" | tail -1 || echo "N/A")
        edges_added=$(grep -oP "(?<=Edges added: )\d+" "$log_file" | tail -1 || echo "N/A")
        total_nodes=$(grep -oP "(?<=Total nodes: )\d+" "$log_file" | tail -1 || echo "N/A")
        total_edges=$(grep -oP "(?<=Total edges: )\d+" "$log_file" | tail -1 || echo "N/A")
        
        # Extract seed sample information
        seed_sample_id=$(grep -oP "(?<=Seed sample ID: )\d+" "$log_file" | tail -1 || echo "N/A")
        seed_sample_name=$(grep -oP "(?<=Seed sample name: ).*" "$log_file" | tail -1 || echo "N/A")
        
        # Extract visualization output path
        viz_path=$(grep -oP "(?<=Output: )Output/.*\.html" "$log_file" | tail -1 || echo "N/A")
        
        # Calculate execution time
        start_time="${{ steps.params.outputs.execution_id }}"
        start_epoch=$(date -d "${start_time:0:8} ${start_time:9:2}:${start_time:11:2}:${start_time:13:2}" +%s 2>/dev/null || echo "0")
        current_epoch=$(date +%s)
        duration_seconds=$((current_epoch - start_epoch))
        duration_minutes=$((duration_seconds / 60))
        
        echo "nodes_added=$nodes_added" >> $GITHUB_OUTPUT
        echo "edges_added=$edges_added" >> $GITHUB_OUTPUT
        echo "total_nodes=$total_nodes" >> $GITHUB_OUTPUT
        echo "total_edges=$total_edges" >> $GITHUB_OUTPUT
        echo "seed_sample_id=$seed_sample_id" >> $GITHUB_OUTPUT
        echo "seed_sample_name=$seed_sample_name" >> $GITHUB_OUTPUT
        echo "viz_path=$viz_path" >> $GITHUB_OUTPUT
        echo "duration_seconds=$duration_seconds" >> $GITHUB_OUTPUT
        echo "duration_minutes=$duration_minutes" >> $GITHUB_OUTPUT
    
    - name: Commit and push changes
      if: steps.orchestration.outputs.can_proceed == 'true' && steps.pipeline.outputs.pipeline_status == 'success'
      run: |
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "** Phase 6: Git Persistence**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Add ONLY visualizations and metrics (NOT checkpoint data)
        git add Output/*.html data/metrics_history.jsonl
        
        # Add milestone-related files if they exist
        if [ -f data/milestone_history.jsonl ]; then
          git add data/milestone_history.jsonl
        fi
        if [ -f validation_report.json ]; then
          git add validation_report.json
        fi
        if [ -f edge_stats.json ]; then
          git add edge_stats.json
        fi
        if [ -d website ]; then
          git add website/
        fi
        
        # Check if there are changes to commit
        if git diff --staged --quiet; then
          echo " No changes to commit"
          echo "- No new visualizations generated" >> $GITHUB_STEP_SUMMARY
        else
          # Create commit message with statistics
          commit_msg="Nightly pipeline: $(date +'%Y-%m-%d')"
          if [ "${{ steps.stats.outputs.nodes_added }}" != "N/A" ]; then
            commit_msg="$commit_msg - +${{ steps.stats.outputs.nodes_added }} nodes, +${{ steps.stats.outputs.edges_added }} edges (total: ${{ steps.stats.outputs.total_nodes }} nodes, ${{ steps.stats.outputs.total_edges }} edges)"
          fi
          
          # Add milestone info to commit message if applicable
          if [ "${{ steps.milestone.outputs.is_milestone }}" = "true" ]; then
            commit_msg="$commit_msg [Milestone ${{ steps.milestone.outputs.milestone_number }}]"
          fi
          
          git commit -m "$commit_msg"
          
          # Push with retry logic
          git push || {
            echo " Push failed, attempting rebase..."
            git pull --rebase
            git push || {
              echo "::error::Failed to push changes after rebase"
              echo "-  Git push failed after retry" >> $GITHUB_STEP_SUMMARY
              exit 1
            }
          }
          
          echo " Changes committed and pushed"
          echo "- Commit: \`$commit_msg\`" >> $GITHUB_STEP_SUMMARY
          echo "- Files: Visualizations, metrics history" >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Cleanup ephemeral cache
      if: always()
      run: |
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "** Phase 7: Cleanup Ephemeral Cache**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Delete checkpoint directory
        if [ -d "data/freesound_library" ]; then
          rm -rf data/freesound_library
          echo " Ephemeral cache wiped"
          echo "- Status: Cache deleted" >> $GITHUB_STEP_SUMMARY
        else
          echo " No cache to clean"
          echo "- Status: No cache found" >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Generate execution summary
      if: always()
      run: |
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "---" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "##  Execution Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check if execution was skipped due to conflicts
        if [ "${{ steps.orchestration.outputs.can_proceed }}" = "false" ]; then
          echo "###  Status: Skipped" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Reason:** ${{ steps.orchestration.outputs.skip_reason }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The workflow detected a conflicting workflow and waited for 2 hours, but it did not complete in time." >> $GITHUB_STEP_SUMMARY
          echo "The workflow will retry on the next scheduled run." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
        elif [ "${{ steps.pipeline.outputs.pipeline_status }}" = "success" ]; then
          echo "###  Status: Success" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Execution time
          duration_min="${{ steps.stats.outputs.duration_minutes }}"
          duration_sec="${{ steps.stats.outputs.duration_seconds }}"
          if [ "$duration_min" != "N/A" ] && [ "$duration_min" -gt 0 ]; then
            echo "** Execution Time:** ${duration_min} minutes (${duration_sec} seconds)" >> $GITHUB_STEP_SUMMARY
          else
            echo "** Execution Time:** ${duration_sec} seconds" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Data collection statistics
          echo "###  Data Collection Statistics" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Nodes Added** | \`${{ steps.stats.outputs.nodes_added }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| **Edges Added** | \`${{ steps.stats.outputs.edges_added }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| **Total Nodes** | \`${{ steps.stats.outputs.total_nodes }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| **Total Edges** | \`${{ steps.stats.outputs.total_edges }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Seed sample information
          if [ "${{ steps.stats.outputs.seed_sample_id }}" != "N/A" ]; then
            echo "** Seed Sample:**" >> $GITHUB_STEP_SUMMARY
            echo "- ID: \`${{ steps.stats.outputs.seed_sample_id }}\`" >> $GITHUB_STEP_SUMMARY
            if [ "${{ steps.stats.outputs.seed_sample_name }}" != "N/A" ]; then
              echo "- Name: \`${{ steps.stats.outputs.seed_sample_name }}\`" >> $GITHUB_STEP_SUMMARY
            fi
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Visualization output
          if [ "${{ steps.stats.outputs.viz_path }}" != "N/A" ]; then
            echo "** Visualization:**" >> $GITHUB_STEP_SUMMARY
            echo "- Path: \`${{ steps.stats.outputs.viz_path }}\`" >> $GITHUB_STEP_SUMMARY
            echo "- [View in Repository](https://github.com/${{ github.repository }}/blob/${{ github.sha }}/${{ steps.stats.outputs.viz_path }})" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
        else
          echo "###  Status: Failed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The pipeline execution failed. Please check the logs for error details." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Common issues:**" >> $GITHUB_STEP_SUMMARY
          echo "- API key not configured or invalid" >> $GITHUB_STEP_SUMMARY
          echo "- API rate limit exceeded" >> $GITHUB_STEP_SUMMARY
          echo "- Network connectivity issues" >> $GITHUB_STEP_SUMMARY
          echo "- Checkpoint file corruption" >> $GITHUB_STEP_SUMMARY
          echo "- BACKUP_PAT not configured or invalid" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Execution details (always shown)
        echo "###  Execution Details" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Detail | Value |" >> $GITHUB_STEP_SUMMARY
        echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
        echo "| **Execution ID** | \`${{ steps.params.outputs.execution_id }}\` |" >> $GITHUB_STEP_SUMMARY
        echo "| **Trigger** | \`${{ github.event_name }}\` |" >> $GITHUB_STEP_SUMMARY
        echo "| **Workflow Run** | [#${{ github.run_number }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) |" >> $GITHUB_STEP_SUMMARY
        echo "| **Commit** | [\`${GITHUB_SHA:0:7}\`](https://github.com/${{ github.repository }}/commit/${{ github.sha }}) |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Artifacts
        echo "###  Artifacts" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- Pipeline logs are available as workflow artifacts (30-day retention)" >> $GITHUB_STEP_SUMMARY
        echo "- Download from the [workflow run page](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
    
    - name: Upload pipeline logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: pipeline-logs-${{ steps.params.outputs.execution_id }}
        path: |
          pipeline_*.log
          freesound_viz_*.log
          fetch_freesound_*.log
          validation.log
          edge_generation.log
          website.log
          milestone_status.json
          validation_report.json
          edge_stats.json
        retention-days: 30
        if-no-files-found: ignore
