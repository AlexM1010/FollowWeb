# Freesound Data Repair Pipeline
#
# Automated pipeline that detects and repairs checkpoint inconsistencies.
# This workflow is part of the three-pipeline architecture:
# 1. Collection Pipeline: Collects data only
# 2. Repair Pipeline (this workflow): Validates and repairs data integrity issues
# 3. Validation & Visualization Pipeline: Generates visualizations from validated data
# 4. Backup Pipeline: Creates and manages backups
#
# Architecture:
# - Triggered automatically after nightly collection completes (continuation)
# - Inherits checkpoint from collection pipeline via cache
# - Can be triggered manually when data issues are detected
# - Restores checkpoint from cache or repository
# - Runs validation checks
# - Applies repairs if validation fails (fetches missing data from API)
# - Re-validates after repairs
# - Saves repaired checkpoint back to cache and repository
#
# Repair Operations:
# - Missing node metadata: Fetches from Freesound API (up to 50 requests)
# - Orphaned metadata: Rebuilds graph nodes from metadata cache
# - Missing pagination state: Adds default pagination state
# - Edge count mismatches: Updates checkpoint metadata
# - Corrupted checkpoint files: Attempts recovery
#
# Required Secrets:
# - FREESOUND_API_KEY: For fetching missing metadata from Freesound API
# - BACKUP_PAT: For uploading repaired checkpoints to backup repository
#
# Features:
# - Automatic trigger after nightly collection (inherits data)
# - Manual trigger with workflow_dispatch
# - Comprehensive validation and repair with API fetching
# - Request limit (50) to prevent excessive API usage
# - Detailed reporting of repairs performed
# - Saves repaired checkpoint for downstream workflows

name: Freesound Data Repair

on:
  workflow_run:
    workflows: ["Freesound Nightly Collection"]
    types: [completed]
    branches: [main]
  
  workflow_dispatch:
    # Allow manual triggering for ad-hoc repairs
    inputs:
      checkpoint_source:
        description: 'Checkpoint source: cache (from last run) or repo (from backup)'
        required: false
        default: 'repo'
        type: choice
        options:
          - cache
          - repo

# Prevent workflow collisions
concurrency:
  group: freesound-repair
  cancel-in-progress: false

permissions:
  contents: read
  issues: write

jobs:
  check-collection-status:
    name: Check Collection Status
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      should_run: ${{ steps.check.outputs.should_run }}
      skip_reason: ${{ steps.check.outputs.skip_reason }}
    
    steps:
    - name: Check if collection ran successfully
      id: check
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # For manual triggers, always run
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          echo "should_run=true" >> "$GITHUB_OUTPUT"
          echo "skip_reason=" >> "$GITHUB_OUTPUT"
          echo "âœ… Manual trigger - proceeding with repair"
          exit 0
        fi
        
        # For workflow_run triggers, check if collection actually ran
        COLLECTION_RUN_ID="${{ github.event.workflow_run.id }}"
        
        # Check if the freesound-collection job actually ran
        JOBS=$(curl -s -H "Authorization: token $GITHUB_TOKEN" \
          -H "Accept: application/vnd.github.v3+json" \
          "https://api.github.com/repos/${{ github.repository }}/actions/runs/$COLLECTION_RUN_ID/jobs")
        
        # Check if freesound-collection job exists and completed successfully
        COLLECTION_JOB=$(echo "$JOBS" | jq -r '.jobs[] | select(.name == "Freesound Data Collection")')
        
        if [ -z "$COLLECTION_JOB" ] || [ "$COLLECTION_JOB" = "null" ]; then
          echo "âš ï¸ Collection job was skipped (likely due to CI check failure)"
          echo "should_run=false" >> "$GITHUB_OUTPUT"
          echo "skip_reason=Collection job was skipped - no data to repair" >> "$GITHUB_OUTPUT"
          
          {
            echo "## âš ï¸ Repair Skipped"
            echo ""
            echo "The collection job was skipped (likely due to CI check failure)."
            echo "No data collection occurred, so repair is not needed."
          } >> "$GITHUB_STEP_SUMMARY"
          exit 0
        fi
        
        JOB_CONCLUSION=$(echo "$COLLECTION_JOB" | jq -r '.conclusion')
        
        if [ "$JOB_CONCLUSION" = "skipped" ]; then
          echo "âš ï¸ Collection job was skipped"
          echo "should_run=false" >> "$GITHUB_OUTPUT"
          echo "skip_reason=Collection job was skipped" >> "$GITHUB_OUTPUT"
          
          {
            echo "## âš ï¸ Repair Skipped"
            echo ""
            echo "The collection job was skipped."
            echo "No data collection occurred, so repair is not needed."
          } >> "$GITHUB_STEP_SUMMARY"
        else
          echo "âœ… Collection job ran - proceeding with repair"
          echo "should_run=true" >> "$GITHUB_OUTPUT"
          echo "skip_reason=" >> "$GITHUB_OUTPUT"
          
          {
            echo "## âœ… Collection Completed"
            echo ""
            echo "Collection job completed with status: $JOB_CONCLUSION"
            echo "Proceeding with repair and validation..."
          } >> "$GITHUB_STEP_SUMMARY"
        fi

  repair-checkpoint:
    name: Validate and Repair Checkpoint
    runs-on: ubuntu-latest
    timeout-minutes: 60
    needs: check-collection-status
    if: needs.check-collection-status.outputs.should_run == 'true'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Configure Git
      run: |
        git config user.name "GitHub Actions Bot"
        git config user.email "actions@github.com"
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: 'FollowWeb/requirements.txt'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        pip install -r FollowWeb/requirements.txt
        pip install -e FollowWeb/
    
    - name: Determine checkpoint source
      id: source
      run: |
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          echo "source=${{ github.event.inputs.checkpoint_source }}" >> "$GITHUB_OUTPUT"
        else
          # For workflow_run trigger, try cache first
          echo "source=cache" >> "$GITHUB_OUTPUT"
        fi
        
        {
          echo "## ðŸ”§ Data Repair Pipeline"
          echo ""
          echo "**Trigger:** \`${{ github.event_name }}\`"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
    
    - name: Restore checkpoint from cache
      if: steps.source.outputs.source == 'cache'
      id: cache_restore
      uses: actions/cache/restore@v3
      with:
        path: data/freesound_library
        key: checkpoint-${{ github.event.workflow_run.id || github.run_id }}
        restore-keys: |
          checkpoint-
    

    
    - name: Check checkpoint availability
      id: checkpoint_check
      run: |
        # Check if we have a checkpoint from either cache or repo
        if [ ! -d "data/freesound_library" ] || [ ! "$(ls -A data/freesound_library 2>/dev/null)" ]; then
          {
            echo "### âš ï¸  No Checkpoint Available"
            echo ""
            echo "This is expected for the first pipeline run."
            echo ""
            echo "**Status:** Skipping repair (no data to repair yet)"
            echo ""
            echo "**Next Steps:**"
            echo "- Collection data will be used directly"
            echo "- Backup workflow will create initial checkpoint"
            echo "- Future runs will have checkpoint available for repair"
          } >> "$GITHUB_STEP_SUMMARY"
          echo "checkpoint_available=false" >> "$GITHUB_OUTPUT"
        else
          echo "checkpoint_available=true" >> "$GITHUB_OUTPUT"
        fi
    
    - name: Run validation checks
      if: steps.checkpoint_check.outputs.checkpoint_available == 'true'
      id: validation
      run: |
        {
          echo "### ðŸ” Validation Checks"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        # Run validation script and capture exit code (use PIPESTATUS to get python exit code, not tee)
        set +e  # Disable exit on error temporarily
        python scripts/validation/validate_checkpoint.py data/freesound_library 2>&1 | tee validation_output.log
        VALIDATION_EXIT_CODE=${PIPESTATUS[0]}
        set -e  # Re-enable exit on error
        
        if [ "$VALIDATION_EXIT_CODE" -eq 0 ]; then
          echo "validation_passed=true" >> "$GITHUB_OUTPUT"
          echo "- Status: âœ… All checks passed" >> "$GITHUB_STEP_SUMMARY"
        else
          echo "validation_passed=false" >> "$GITHUB_OUTPUT"
          echo "- Status: âŒ Validation failed" >> "$GITHUB_STEP_SUMMARY"
        fi
        echo "" >> "$GITHUB_STEP_SUMMARY"
    
    - name: Determine max_requests for repair
      if: steps.validation.outputs.validation_passed == 'false'
      id: max_requests
      run: |
        # Try to read max_requests from checkpoint metadata (saved by collection)
        # Fall back to 13 (same as nightly collection default)
        MAX_REQUESTS=13
        
        if [ -f "data/freesound_library/checkpoint_metadata.json" ]; then
          # Try to extract from checkpoint metadata using Python
          CHECKPOINT_MAX=$(python3 -c 'import json; data=json.load(open("data/freesound_library/checkpoint_metadata.json")); print(data.get("collection_stats", {}).get("max_requests", 13))' 2>/dev/null || echo "13")
          
          if [ "$CHECKPOINT_MAX" -gt 0 ]; then
            MAX_REQUESTS=$CHECKPOINT_MAX
          fi
        fi
        
        echo "max_requests=$MAX_REQUESTS" >> "$GITHUB_OUTPUT"
        echo "Using max_requests: $MAX_REQUESTS (from checkpoint metadata or default)"
    
    - name: Run comprehensive data quality repair
      if: steps.validation.outputs.validation_passed == 'false'
      id: repair
      env:
        FREESOUND_API_KEY: ${{ secrets.FREESOUND_API_KEY }}
      run: |
        MAX_REQUESTS="${{ steps.max_requests.outputs.max_requests }}"
        
        {
          echo "### ðŸ”§ Comprehensive Data Quality Repair"
          echo ""
          echo "Scanning ALL samples for data quality issues..."
          echo "- Checks all fields in all samples"
          echo "- Queues issues by sample ID (up to 150 per batch)"
          echo "- Fetches missing data using efficient batch API"
          echo "- Applies fixes across entire dataset"
          echo "- Max requests: \`${MAX_REQUESTS}\` (same as collection)"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        # Run comprehensive data quality repair with same max_requests as collection
        # This script checks ALL samples and ALL fields, then fixes issues in batches
        if python scripts/validation/comprehensive_data_repair.py \
          --checkpoint-dir data/freesound_library \
          --api-key "$FREESOUND_API_KEY" \
          --max-requests "${MAX_REQUESTS}" \
          2>&1 | tee comprehensive_repair_output.log; then
          echo "repair_success=true" >> "$GITHUB_OUTPUT"
          
          # Extract statistics from log
          issues_found=$(grep -oP "(?<=Issues found: )\d+" comprehensive_repair_output.log | tail -1 || echo "0")
          issues_fixed=$(grep -oP "(?<=Issues fixed: )\d+" comprehensive_repair_output.log | tail -1 || echo "0")
          marked_unavailable=$(grep -oP "(?<=Marked unavailable: )\d+" comprehensive_repair_output.log | tail -1 || echo "0")
          api_requests=$(grep -oP "(?<=API requests used: )\d+" comprehensive_repair_output.log | tail -1 || echo "0")
          
          {
            echo "**Results:**"
            echo "- Issues found: \`${issues_found}\`"
            echo "- Issues fixed: \`${issues_fixed}\`"
            echo "- Marked unavailable: \`${marked_unavailable}\`"
            echo "- API requests used: \`${api_requests}/${MAX_REQUESTS}\`"
            echo ""
            echo "âœ… Comprehensive repair completed successfully"
          } >> "$GITHUB_STEP_SUMMARY"
        else
          echo "repair_success=false" >> "$GITHUB_OUTPUT"
          echo "- Status: âŒ Comprehensive repair failed" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        echo "" >> "$GITHUB_STEP_SUMMARY"
    
    - name: Re-validate after repairs
      if: steps.repair.outputs.repair_success == 'true'
      id: revalidation
      run: |
        {
          echo "### ðŸ” Re-validation After Repairs"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        # Run validation again
        if python scripts/validation/validate_checkpoint.py data/freesound_library; then
          echo "revalidation_passed=true" >> "$GITHUB_OUTPUT"
          echo "- Status: âœ… All checks passed" >> "$GITHUB_STEP_SUMMARY"
        else
          echo "revalidation_passed=false" >> "$GITHUB_OUTPUT"
          {
            echo "- Status: âŒ Validation still failing"
            echo ""
            echo "**Warning:** Repairs did not resolve all issues. Manual intervention may be required."
          } >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        echo "" >> "$GITHUB_STEP_SUMMARY"
    
    # Debug: List checkpoint files before caching
    - name: Debug - List checkpoint files
      if: always() && (steps.validation.outputs.validation_passed == 'true' || (steps.repair.outputs.repair_success == 'true' && steps.revalidation.outputs.revalidation_passed == 'true'))
      run: |
        echo "Listing checkpoint directory contents:"
        ls -laR data/freesound_library/ || echo "Directory not found"
        echo ""
        echo "File sizes:"
        du -h data/freesound_library/* || echo "No files found"
        echo ""
        echo "Total directory size:"
        du -sh data/freesound_library/ || echo "Directory not found"
    
    # Save to cache as SECONDARY backup (after permanent storage)
    # Cache has 7-day retention and should only be used as fallback
    - name: Save checkpoint to cache (SECONDARY backup - for downstream workflows)
      if: always() && (steps.validation.outputs.validation_passed == 'true' || (steps.repair.outputs.repair_success == 'true' && steps.revalidation.outputs.revalidation_passed == 'true'))
      id: cache_save
      uses: actions/cache/save@v3
      with:
        path: data/freesound_library
        key: checkpoint-repaired-${{ github.run_id }}
    
    - name: Verify cache integrity and warn if permanent storage failed
      if: always() && (steps.validation.outputs.validation_passed == 'true' || (steps.repair.outputs.repair_success == 'true' && steps.revalidation.outputs.revalidation_passed == 'true'))
      run: |
        {
          echo "### ðŸ” Cache Verification"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        # Verify checkpoint files exist
        CHECKPOINT_DIR="data/freesound_library"
        
        if [ ! -d "$CHECKPOINT_DIR" ]; then
          echo "::error::Checkpoint directory not found"
          echo "- âŒ Directory not found" >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        # Check all three required files
        missing_files=0
        
        if [ ! -f "$CHECKPOINT_DIR/graph_topology.gpickle" ]; then
          echo "::error::Missing graph_topology.gpickle"
          echo "- âŒ Missing: graph_topology.gpickle" >> "$GITHUB_STEP_SUMMARY"
          missing_files=$((missing_files + 1))
        else
          graph_size=$(stat -f%z "$CHECKPOINT_DIR/graph_topology.gpickle" 2>/dev/null || stat -c%s "$CHECKPOINT_DIR/graph_topology.gpickle")
          echo "- âœ… graph_topology.gpickle ($(numfmt --to=iec-i --suffix=B "$graph_size"))" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        if [ ! -f "$CHECKPOINT_DIR/metadata_cache.db" ]; then
          echo "::error::Missing metadata_cache.db"
          echo "- âŒ Missing: metadata_cache.db" >> "$GITHUB_STEP_SUMMARY"
          missing_files=$((missing_files + 1))
        else
          db_size=$(stat -f%z "$CHECKPOINT_DIR/metadata_cache.db" 2>/dev/null || stat -c%s "$CHECKPOINT_DIR/metadata_cache.db")
          echo "- âœ… metadata_cache.db ($(numfmt --to=iec-i --suffix=B "$db_size"))" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        if [ ! -f "$CHECKPOINT_DIR/checkpoint_metadata.json" ]; then
          echo "::error::Missing checkpoint_metadata.json"
          echo "- âŒ Missing: checkpoint_metadata.json" >> "$GITHUB_STEP_SUMMARY"
          missing_files=$((missing_files + 1))
        else
          meta_size=$(stat -f%z "$CHECKPOINT_DIR/checkpoint_metadata.json" 2>/dev/null || stat -c%s "$CHECKPOINT_DIR/checkpoint_metadata.json")
          echo "- âœ… checkpoint_metadata.json ($(numfmt --to=iec-i --suffix=B "$meta_size"))" >> "$GITHUB_STEP_SUMMARY"
        fi
        
        if [ "$missing_files" -gt 0 ]; then
          echo "::error::Cache save verification failed - $missing_files files missing"
          {
            echo ""
            echo "âš ï¸ **WARNING**: Cache was saved but is incomplete!"
            echo "âš ï¸ **Downstream workflows may fail!**"
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"
          exit 1
        fi
        
        # Cache saved successfully
        {
          echo ""
          echo "âœ… All checkpoint files verified"
          echo "âœ… Cache key: \`checkpoint-repaired-${{ github.run_id }}\`"
          echo ""
          echo "### âœ… Data Persistence Status"
          echo "- Cache: âœ… Saved (7-day retention)"
          echo "- Permanent storage: â³ Will be handled by backup workflow"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
    
    - name: Generate repair summary
      if: always()
      run: |
        {
          echo "---"
          echo ""
          echo "## ðŸ“Š Repair Summary"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
        
        if [ "${{ steps.checkpoint_check.outputs.checkpoint_available }}" = "false" ]; then
          {
            echo "### â„¹ï¸  No Checkpoint Available"
            echo ""
            echo "This is expected for the first pipeline run."
            echo ""
            echo "**Status:** Skipped repair (no data to repair yet)"
            echo ""
            echo "**Next Steps:**"
            echo "- Collection data will be used directly"
            echo "- Backup workflow will create initial checkpoint"
            echo "- Future runs will have checkpoint available for repair"
          } >> "$GITHUB_STEP_SUMMARY"
        elif [ "${{ steps.validation.outputs.validation_passed }}" = "true" ]; then
          {
            echo "### âœ… No Repairs Needed"
            echo ""
            echo "All validation checks passed. Checkpoint is healthy."
          } >> "$GITHUB_STEP_SUMMARY"
        elif [ "${{ steps.repair.outputs.repair_success }}" = "true" ] && [ "${{ steps.revalidation.outputs.revalidation_passed }}" = "true" ]; then
          {
            echo "### âœ… Repairs Successful"
            echo ""
            echo "Checkpoint issues were detected and successfully repaired."
            echo ""
            echo "**Actions Taken:**"
            echo "- Validation identified issues"
            echo "- Repair operations applied"
            echo "- Re-validation confirmed fixes"
            echo "- Repaired checkpoint uploaded to backup repository"
          } >> "$GITHUB_STEP_SUMMARY"
        elif [ "${{ steps.repair.outputs.repair_success }}" = "false" ]; then
          {
            echo "### âŒ Repairs Failed"
            echo ""
            echo "Repair operations failed. Manual intervention required."
          } >> "$GITHUB_STEP_SUMMARY"
        elif [ "${{ steps.revalidation.outputs.revalidation_passed }}" = "false" ]; then
          {
            echo "### âš ï¸ Partial Repair"
            echo ""
            echo "Repairs were applied but validation still fails. Additional investigation needed."
          } >> "$GITHUB_STEP_SUMMARY"
        else
          {
            echo "### âŒ Repair Pipeline Error"
            echo ""
            echo "An unexpected error occurred during the repair process."
          } >> "$GITHUB_STEP_SUMMARY"
        fi
        
        {
          echo ""
          echo "### ðŸ“‹ Execution Details"
          echo ""
          echo "| Detail | Value |"
          echo "|--------|-------|"
          echo "| **Workflow Run** | [#${{ github.run_number }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) |"
          echo "| **Trigger** | \`${{ github.event_name }}\` |"
        } >> "$GITHUB_STEP_SUMMARY"
        if [ "${{ github.event_name }}" = "workflow_run" ]; then
          echo "| **Source Workflow** | [Run #${{ github.event.workflow_run.run_number }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.event.workflow_run.id }}) |" >> "$GITHUB_STEP_SUMMARY"
        fi
        {
          echo "| **Checkpoint Source** | \`${{ steps.source.outputs.source }}\` |"
          echo ""
        } >> "$GITHUB_STEP_SUMMARY"
    
    - name: Upload repair logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: repair-logs-${{ github.run_id }}
        path: |
          *.log
          validation_output.log
          repair_output.log
        retention-days: 30
        if-no-files-found: ignore
    
    - name: Mark workflow as successful if no checkpoint available
      if: steps.checkpoint_check.outputs.checkpoint_available == 'false'
      run: |
        echo "âœ… Workflow completed successfully (no checkpoint to repair)"
        exit 0
    
    - name: Create issue on failure
      if: failure()
      continue-on-error: true
      uses: actions/github-script@v7
      with:
        script: |
          const issue_body = `## ðŸ”§ Repair Pipeline Failed
          
          The data repair pipeline encountered an error and could not complete successfully.
          
          ### Details
          - **Workflow Run:** [#${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
          - **Trigger:** \`${{ github.event_name }}\`
          - **Branch:** \`${{ github.ref_name }}\`
          - **Timestamp:** ${new Date().toISOString()}
          
          ### Possible Causes
          - Checkpoint files corrupted beyond repair
          - Database connection issues
          - Insufficient disk space
          - Network connectivity problems
          
          ### Next Steps
          1. Review the [workflow logs](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
          2. Download repair logs from artifacts
          3. Check checkpoint integrity manually
          4. Consider restoring from backup if needed
          
          ### Artifacts
          - Repair logs available in workflow artifacts (30-day retention)
          
          ---
          *This issue was automatically created by the repair pipeline.*`;
          
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `ðŸ”§ Repair Pipeline Failed - Run #${{ github.run_number }}`,
            body: issue_body,
            labels: ['automated', 'repair-failure', 'needs-investigation']
          });
