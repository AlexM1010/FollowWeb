[pytest]
# Pytest configuration for FollowWeb parallel testing

# Test discovery patterns
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Parallel execution with automatic device adaptation
# - pytest-xdist auto-detects CPU count
# - conftest.py applies memory-based limits
# - Works on any device without configuration
addopts = 
    --verbose
    --tb=short
    --strict-markers
    --capture=sys

# Test markers for categorization
markers =
    unit: Unit tests (fast, isolated) - maximum parallelization
    integration: Integration tests (slower, cross-module) - controlled parallelization  
    slow: Slow tests (performance, timing) - sequential execution
    performance: Performance benchmarking tests
    benchmark: Benchmark tests (require sequential execution, no xdist)
    final_validation: Final validation tests for complete workflows
    
    # Granular category markers for parallel execution optimization
    core: Core functionality tests (config, types, exceptions)
    data: Data loading and processing tests
    analysis: Network analysis algorithm tests
    visualization: Rendering and visualization tests
    output: Output formatting and logging tests
    utils: Utility function tests
    pipeline: End-to-end pipeline tests

# Timeout configuration (adjusted for parallel execution overhead)
timeout = 300
timeout_method = thread

# Minimum pytest version
minversion = 6.0

# Parallel-safe temporary directory handling
tmp_path_retention_count = 3
tmp_path_retention_policy = failed

# Logging configuration for parallel execution
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s (%(filename)s:%(lineno)d)
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Memory optimization
# - Automatic garbage collection after each test (configured in conftest.py)
# - Memory-aware worker limits based on available RAM
# - Max worker restart limit to prevent runaway memory from crashed workers
# - Integration tests use ~500MB per worker, unit tests use ~200MB per worker

# Benchmark-specific configuration - removed invalid options

# Warnings configuration - removed filters to see actual warnings